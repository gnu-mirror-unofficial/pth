<html>
<head>
<title>GNU Pth - The GNU Portable Threads</title>
<style type="text/css"><!--
A:link { color: #3333FF; }
A:active { color: #3333FF; }
A:visited { color: #3333FF; }
#sf { font-family: arial,helvetica; font-variant: normal; font-style: normal; }
#sfh { font-weight: bold; font-size: 18pt; line-height: 18pt; font-family: arial,helvetica; font-variant: normal; font-style: normal; }
H1 { font-weight: bold; font-size: 18pt; line-height: 18pt; font-family: arial,helvetica; font-variant: normal; font-style: normal; }
H2 { font-weight: bold; font-size: 14pt; line-height: 14pt; font-family: arial,helvetica; font-variant: normal; font-style: normal; }
H3 { font-weight: bold; font-size: 12pt; line-height: 12pt; font-family: arial,helvetica; font-variant: normal; font-style: normal; }
--></style>
</head>
<body bgcolor="#FFFFFF" text="#000000" link="#3333FF" alink="#FF0000" vlink="#3333FF">
<blockquote>
<blockquote>
<img src="pth.jpg" alt="GNU Portable Threads" width="496" height="198">
<p>
<DIV id="sfh">
  GNU Pth - The GNU Portable Threads
</div>
<DIV id="sf">
  Copyright &copy; 1999-2000
  <a href="http://www.gnu.org/people/people.html">Ralf S. Engelschall</a>
  &lt;<a href="mailto:rse@gnu.org">rse@gnu.org</a>&gt;
</div>
<!-- INDEX BEGIN -->
<UL>
	<LI><A HREF="#NAME">NAME</A>
	<LI><A HREF="#VERSION">VERSION</A>
	<LI><A HREF="#SYNOPSIS">SYNOPSIS</A>
	<LI><A HREF="#DESCRIPTION">DESCRIPTION</A>
	<UL>
		<LI><A HREF="#Threading_Background">Threading Background</A>
		<LI><A HREF="#The_World_of_Threading">The World of Threading</A>
		<LI><A HREF="#User_Space_Threads">User-Space Threads</A>
		<LI><A HREF="#The_Compromise_of_Pth">The Compromise of Pth</A>
		<LI><A HREF="#The_life_cycle_of_a_thread">The life cycle of a thread</A>
	</UL>
	<LI><A HREF="#APPLICATION_PROGRAMMING_INTERFAC">APPLICATION PROGRAMMING INTERFACE (API)</A>
	<UL>
		<LI><A HREF="#Global_Library_Management">Global Library Management</A>
		<LI><A HREF="#Thread_Attribute_Handling">Thread Attribute Handling</A>
		<LI><A HREF="#Thread_Control">Thread Control</A>
		<LI><A HREF="#Utilities">Utilities</A>
		<LI><A HREF="#Cancellation_Management">Cancellation Management</A>
		<LI><A HREF="#Event_Handling">Event Handling</A>
		<LI><A HREF="#Key_Based_Storage">Key-Based Storage</A>
		<LI><A HREF="#Message_Port_Communication">Message Port Communication</A>
		<LI><A HREF="#Thread_Cleanups">Thread Cleanups</A>
		<LI><A HREF="#Process_Forking">Process Forking</A>
		<LI><A HREF="#Synchronization">Synchronization</A>
		<LI><A HREF="#Generalized_POSIX_Replacement_AP">Generalized POSIX Replacement API</A>
		<LI><A HREF="#Standard_POSIX_Replacement_API">Standard POSIX Replacement API</A>
	</UL>
	<LI><A HREF="#EXAMPLE">EXAMPLE</A>
	<LI><A HREF="#BUILD_ENVIRONMENTS">BUILD ENVIRONMENTS</A>
	<UL>
		<LI><A HREF="#Manual_Build_Environment_Novice">Manual Build Environment (Novice)</A>
		<LI><A HREF="#Autoconf_Build_Environment_Adva">Autoconf Build Environment (Advanced)</A>
		<LI><A HREF="#Autoconf_Build_Environment_with_">Autoconf Build Environment with Local Copy of Pth (Expert)</A>
	</UL>
	<LI><A HREF="#SYSTEM_CALL_WRAPPER_FACILITY">SYSTEM CALL WRAPPER FACILITY</A>
	<UL>
		<LI><A HREF="#Soft_System_Call_Mapping">Soft System Call Mapping</A>
		<LI><A HREF="#Hard_System_Call_Mapping">Hard System Call Mapping</A>
	</UL>
	<LI><A HREF="#IMPLEMENTATION_NOTES">IMPLEMENTATION NOTES</A>
	<LI><A HREF="#RESTRICTIONS">RESTRICTIONS</A>
	<LI><A HREF="#HISTORY">HISTORY</A>
	<LI><A HREF="#BUG_REPORTS_AND_SUPPORT">BUG REPORTS AND SUPPORT</A>
	<LI><A HREF="#SEE_ALSO">SEE ALSO</A>
	<UL>
		<LI><A HREF="#Related_Web_Locations">Related Web Locations</A>
		<LI><A HREF="#Related_Books">Related Books</A>
		<LI><A HREF="#Related_Manpages">Related Manpages</A>
	</UL>
	<LI><A HREF="#AUTHOR">AUTHOR</A>
</UL>
<!-- INDEX END -->
<P>
<H1><A NAME="NAME"><font face="Arial,Helvetica">NAME</A></H1></font>
<P>
<STRONG>pth</STRONG> -
<FONT SIZE="-1">GNU</FONT> Portable Threads
<P>
<H1><A NAME="VERSION"><font face="Arial,Helvetica">VERSION</A></H1></font>
<P>
<FONT SIZE="-1">GNU</FONT> Pth
<FONT SIZE="-1">PTH_VERSION_STR</FONT>
<P>
<H1><A NAME="SYNOPSIS"><font face="Arial,Helvetica">SYNOPSIS</A></H1></font>
<DL>
<DT><P><STRONG><A NAME="item_Global">Global Library Management</A></STRONG><DD>
pth_init, pth_kill, pth_ctrl, pth_version.
<DT><P><STRONG><A NAME="item_Thread">Thread Attribute Handling</A></STRONG><DD>
pth_attr_of, pth_attr_new, pth_attr_init, pth_attr_set, pth_attr_get,
pth_attr_destroy.
<DT><P><STRONG>Thread Control</STRONG><DD>
pth_spawn, pth_once, pth_self, pth_suspend, pth_resume, pth_yield, pth_nap,
pth_wait, pth_cancel, pth_abort, pth_raise, pth_join, pth_exit.
<DT><P><STRONG><A NAME="item_Utilities">Utilities</A></STRONG><DD>
pth_fdmode, pth_time, pth_timeout, pth_sfiodisc.
<DT><P><STRONG><A NAME="item_Cancellation">Cancellation Management</A></STRONG><DD>
pth_cancel_point, pth_cancel_state.
<DT><P><STRONG><A NAME="item_Event">Event Handling</A></STRONG><DD>
pth_event, pth_event_typeof, pth_event_extract, pth_event_concat,
pth_event_isolate, pth_event_walk, pth_event_occurred, pth_event_free.
<DT><P><STRONG><A NAME="item_Key">Key-Based Storage</A></STRONG><DD>
pth_key_create, pth_key_delete, pth_key_setdata, pth_key_getdata.
<DT><P><STRONG><A NAME="item_Message">Message Port Communication</A></STRONG><DD>
pth_msgport_create, pth_msgport_destroy, pth_msgport_find,
pth_msgport_pending, pth_msgport_put, pth_msgport_get, pth_msgport_reply.
<DT><P><STRONG>Thread Cleanups</STRONG><DD>
pth_cleanup_push, pth_cleanup_pop.
<DT><P><STRONG><A NAME="item_Process">Process Forking</A></STRONG><DD>
pth_atfork_push, pth_atfork_pop, pth_fork.
<DT><P><STRONG><A NAME="item_Synchronization">Synchronization</A></STRONG><DD>
pth_mutex_init, pth_mutex_acquire, pth_mutex_release, pth_rwlock_init,
pth_rwlock_acquire, pth_rwlock_release, pth_cond_init, pth_cond_await,
pth_cond_notify, pth_barrier_init, pth_barrier_reach.
<DT><P><STRONG><A NAME="item_Generalized">Generalized POSIX Replacement API</A></STRONG><DD>
pth_sigwait_ev, pth_accept_ev, pth_connect_ev, pth_select_ev, pth_poll_ev,
pth_read_ev, pth_readv_ev, pth_write_ev, pth_writev_ev.
<DT><P><STRONG><A NAME="item_Standard">Standard POSIX Replacement API</A></STRONG><DD>
pth_usleep, pth_sleep, pth_waitpid, pth_sigmask, pth_sigwait, pth_accept,
pth_connect, pth_select, pth_poll, pth_read, pth_readv, pth_write,
pth_writev, pth_pread, pth_pwrite.
</DL>
<P>
<H1><A NAME="DESCRIPTION"><font face="Arial,Helvetica">DESCRIPTION</A></H1></font>
<P>
<PRE>  ____  _   _
 |  _ \| |_| |__
 | |_) | __| '_ \         ``Only those who attempt
 |  __/| |_| | | |          the absurd can achieve
 |_|    \__|_| |_|          the impossible.''
</PRE>
<P>
<STRONG>Pth</STRONG> is a very portable
<FONT SIZE="-1">POSIX/ANSI-C</FONT> based library for Unix platforms which
provides non-preemptive priority-based scheduling for multiple threads of
execution (aka `multithreading') inside event-driven applications. All
threads run in the same address space of the application process, but each
thread has its own individual program counter, run-time stack, signal mask
and <CODE>errno</CODE>
variable.
<P>
The thread scheduling itself is done in a cooperative way, i.e., the threads are managed and dispatched by a priority- and event-driven non-preemptive scheduler. The intention is that this way both better portability and run-time performance is achieved than with preemptive scheduling. The event facility allows threads to wait until various types of internal and external events occur, including pending
<FONT SIZE="-1">I/O</FONT> on file descriptors, asynchronous signals, elapsed timers, pending
<FONT SIZE="-1">I/O</FONT> on message ports, thread and process termination, and even results of customized callback functions.
<P>
<STRONG>Pth</STRONG> also provides an optional emulation
<FONT SIZE="-1">API</FONT> for POSIX.1c threads (`Pthreads') which can be
used for backward compatibility to existing multithreaded applications. See <STRONG>Pth</STRONG>'s <CODE>pthread(3)</CODE> manual page for details.
<P>
<H2><A NAME="Threading_Background"><font face="Arial,Helvetica">Threading Background</A></H2></font>
<P>
When programming event-driven applications, usually servers, lots of
regular jobs and one-shot requests have to be processed in parallel. To
efficiently simulate this parallel processing on uniprocessor machines, we
use `multitasking' -- that is, we have the application ask the operating
system to spawn multiple instances of itself. On Unix, typically the kernel
implements multitasking in a preemptive and priority-based way through
heavy-weight processes spawned with <CODE>fork(2).</CODE> These processes
usually do <EM>not</EM> share a common address space. Instead they are clearly separated from each
other, and are created by direct cloning a process address space (although
modern kernels use memory segment mapping and copy-on-write semantics to
avoid unnecessary copying of physical memory).
<P>
The drawbacks are obvious: Sharing data between the processes is
complicated, and can usually only be done efficiently through shared memory
(but which itself is not very portable). Synchronization is complicated
because of the preemptive nature of the Unix scheduler (one has to use <EM>atomic</EM> locks, etc). The machine's resources can be exhausted very quickly when the
server application has to serve too many long-running requests
(heavy-weight processes cost memory). And when each request spawns a
sub-process to handle it, the server performance and responsiveness is
horrible (heavy-weight processes cost time to spawn). Finally, the server
application doesn't scale very well with the load because of these resource
problems. In practice, lots of tricks are usually used to overcome these
problems - ranging from pre-forked sub-process pools to semi-serialized
processing, etc.
<P>
One of the most elegant ways to solve these resource- and data-sharing
problems is to have multiple <EM>light-weight</EM> threads of execution inside a single (heavy-weight) process, i.e., to use <EM>multithreading</EM>. Those <EM>threads</EM> usually improve responsiveness and performance of the application, often
improve and simplify the internal program structure, and most important,
require less system resources than heavy-weight processes. Threads are
neither the optimal run-time facility for all types of applications, nor
can all applications benefit from them. But at least event-driven server
applications usually benefit greatly from using threads.
<P>
<H2><A NAME="The_World_of_Threading"><font face="Arial,Helvetica">The World of Threading</A></H2></font>
<P>
Even though lots of documents exists which describe and define the world of
threading, to understand <STRONG>Pth</STRONG>, you need only basic knowledge about threading. The following definitions
of thread-related terms should at least help you understand thread
programming enough to allow you to use
<STRONG>Pth</STRONG>.
<DL>
<DT><P><STRONG><A NAME="item_o">o process vs. thread</A></STRONG><DD>
<FONT SIZE="-1">A</FONT> process on Unix systems consists of at least the
following fundamental ingredients: <EM>virtual memory table</EM>, <EM>program code</EM>, <EM>program
counter</EM>, <EM>heap memory</EM>, <EM>stack memory</EM>, <EM>stack pointer</EM>, <EM>file
descriptor set</EM>, <EM>signal table</EM>. On every process switch, the kernel saves and restores these ingredients
for the individual processes. On the other hand, a thread consists of only
a private program counter, stack memory, stack pointer and signal table.
All other ingredients, in particular the virtual memory, it shares with the
other threads of the same process.
<DT><P><STRONG>o kernel-space vs. user-space threading</STRONG><DD>
Threads on a Unix platform traditionally can be implemented either inside
kernel-space or user-space. When threads are implemented by the kernel, the
thread context switches are performed by the kernel without the
application's knowledge. Similarly, when threads are implemented in
user-space, the thread context switches are performed by an application
library, without the kernel's knowledge. There also are hybrid threading
approaches where, typically, a user-space library binds one or more
user-space threads to one or more kernel-space threads (there usually
called light-weight processes - or in short LWPs).
<P>
User-space threads are usually more portable and can perform faster and cheaper context switches (for instance via <CODE>swapcontext(2)</CODE> or <CODE>setjmp(3)/longjmp(3))</CODE> than kernel based threads. On the other hand, kernel-space threads can take advantage of multiprocessor machines and don't have any inherent
<FONT SIZE="-1">I/O</FONT> blocking problems. Kernel-space threads are usually scheduled in preemptive way side-by-side with the underlying processes. User-space threads on the other hand use either preemptive or non-preemptive scheduling.
<DT><P><STRONG>o preemtive vs. non-preemtive thread scheduling</STRONG><DD>
In preemptive scheduling, the scheduler lets a thread execute until a
blocking situation occurs (usually a function call which would block) or
the assigned timeslice elapses. Then it detracts control from the thread
without a chance for the thread to object. This is usually realized by
interrupting the thread through a hardware interrupt signal (for
kernel-space threads) or a software interrupt signal (for user-space
threads), like <CODE>SIGALRM</CODE> or <CODE>SIGVTALRM</CODE>. In non-preemptive scheduling, once a thread received control from the
scheduler it keeps it until either a blocking situation occurs (again a
function call which would block and instead switches back to the scheduler)
or the thread explicitly yields control back to the scheduler in a
cooperative way.
<DT><P><STRONG>o concurrency vs. parallelism</STRONG><DD>
Concurrency exists when at least two threads are <EM>in progress</EM> at the same time. Parallelism arises when at least two threads are <EM>executing</EM>
simultaneously. Real parallelism can be only achieved on multiprocessor
machines, of course. But one also usually speaks of parallelism or
<EM>high concurrency</EM> in the context of preemptive thread scheduling and of <EM>low concurrency</EM> in the context of non-preemptive thread scheduling.
<DT><P><STRONG>o responsiveness</STRONG><DD>
The responsiveness of a system can be described by the user visible delay
until the system responses to an external request. When this delay is small
enough and the user doesn't recognize a noticeable delay, the
responsiveness of the system is considered good. When the user recognizes
or is even annoyed by the delay, the responsiveness of the system is
considered bad.
<DT><P><STRONG>o reentrant, thread-safe and asynchronous-safe functions</STRONG><DD>
<FONT SIZE="-1">A</FONT> reentrant function is one that behaves correctly if
it is called simultaneously by several threads and then also executes
simultaneously. Functions that access global state, such as memory or
files, of course, need to be carefully designed in order to be reentrant.
Two traditional approaches to solve these problems are caller-supplied
states and thread-specific data.
<P>
Thread-safety is the avoidance of <EM>data races</EM>, i.e., situations in which data is set to either correct or incorrect
value depending upon the (unpredictable) order in which multiple threads
access and modify the data. So a function is thread-safe when it still
behaves semantically correct when called simultaneously by several threads
(it is not required that the functions also execute simultaneously). The
traditional approach to achieve thread-safety is to wrap a function body
with an internal mutual exclusion lock (aka `mutex'). As you should
recognize, reentrant is a stronger attribute than thread-safe, because it
is harder to achieve and results especially in no run-time contention
between threads. So, a reentrant function is always thread-safe, but not
vice versa.
<P>
Additionally there is a related attribute for functions named asynchronous-safe, which comes into play in conjunction with signal handlers. This is very related to the problem of reentrant functions. An asynchronous-safe function is one that can be called safe and without side-effects from within a signal handler context. Usually very few functions are of this type, because an application is very restricted in what it can perform from within a signal handler (especially what system functions it is allowed to call). The reason mainly is, because only a few system functions are officially declared by
<FONT SIZE="-1">POSIX</FONT> as guaranteed to be asynchronous-safe. Asynchronous-safe functions usually have to be already reentrant.
</DL>
<P>
<H2><A NAME="User_Space_Threads"><font face="Arial,Helvetica">User-Space Threads</A></H2></font>
<P>
User-space threads can be implemented in various way. The two traditional
approaches are:
<OL>
<LI><STRONG><A NAME="item__">.</A></STRONG>
<P>
<STRONG>Matrix-based explicit dispatching between small units of execution:</STRONG>
<P>
Here the global procedures of the application are split into small
execution units (each is required to not run for more than a few
milliseconds) and those units are implemented by separate functions. Then a
global matrix is defined which describes the execution (and perhaps even
dependency) order of these functions. The main server procedure then just
dispatches between these units by calling one function after each other
controlled by this matrix. The threads are created by more than one
jump-trail through this matrix and by switching between these jump-trails
controlled by corresponding occurred events.
<P>
This approach gives the best possible performance, because one can fine-tune the threads of execution by adjusting the matrix, and the scheduling is done explicitly by the application itself. It is also very portable, because the matrix is just an ordinary data structure, and functions are a standard feature of
<FONT SIZE="-1">ANSI</FONT>
<FONT SIZE="-1">C.</FONT>
<P>
The disadvantage of this approach is that it is complicated to write large
applications with this approach, because in those applications one quickly
gets <CODE>hundreds(!)</CODE> of execution units and the control flow
inside such an application is very hard to understand (because it is
interrupted by function borders and one always has to remember the global
dispatching matrix to follow it). Additionally, all threads operate on the
same execution stack. Although this saves memory, it is often nasty,
because one cannot switch between threads in the middle of a function. Thus
the scheduling borders are the function borders.
<LI><STRONG>.</STRONG>
<P>
<STRONG>Context-based implicit scheduling between threads of execution:</STRONG>
<P>
Here the idea is that one programs the application as with forked
processes, i.e., one spawns a thread of execution and this runs from the
begin to the end without an interrupted control flow. But the control flow
can be still interrupted - even in the middle of a function. Actually in a
preemptive way, similar to what the kernel does for the heavy-weight
processes, i.e., every few milliseconds the user-space scheduler switches
between the threads of execution. But the thread itself doesn't recognize
this and usually (except for synchronization issues) doesn't have to care
about this.
<P>
The advantage of this approach is that it's very easy to program, because
the control flow and context of a thread directly follows a procedure
without forced interrupts through function borders. Additionally, the
programming is very similar to a traditional and well understood
<CODE>fork(2)</CODE> based approach.
<P>
The disadvantage is that although the general performance is increased, compared to using approaches based on heavy-weight processes, it is decreased compared to the matrix-approach above. Because the implicit preemptive scheduling does usually a lot more context switches (every user-space context switch costs some overhead even when it is a lot cheaper than a kernel-level context switch) than the explicit cooperative/non-preemptive scheduling. Finally, there is no really portable
<FONT SIZE="-1">POSIX/ANSI-C</FONT> based way to implement user-space preemptive threading. Either the platform already has threads, or one has to hope that some semi-portable package exists for it. And even those semi-portable packages usually have to deal with assembler code and other nasty internals and are not easy to port to forthcoming platforms.
</OL>
<P>
So, in short: the matrix-dispatching approach is portable and fast, but
nasty to program. The thread scheduling approach is easy to program, but
suffers from synchronization and portability problems caused by its
preemptive nature.
<P>
<H2><A NAME="The_Compromise_of_Pth"><font face="Arial,Helvetica">The Compromise of Pth</A></H2></font>
<P>
But why not combine the good aspects of both approaches while avoiding
their bad aspects? That's the goal of <STRONG>Pth</STRONG>. <STRONG>Pth</STRONG> implements easy-to-program threads of execution, but avoids the problems of
preemptive scheduling by using non-preemptive scheduling instead.
<P>
This sounds like, and is, a useful approach. Nevertheless, one has to keep
the implications of non-preemptive thread scheduling in mind when working
with <STRONG>Pth</STRONG>. The following list summarizes a few essential points:
<DL>
<DT><P><STRONG>o</STRONG><DD>
<STRONG>Pth provides maximum portability, but NOT the fanciest features</STRONG>.
<P>
This is, because it uses a nifty and portable
<FONT SIZE="-1">POSIX/ANSI-C</FONT> approach for thread creation (and this
way doesn't require any platform dependent assembler hacks) and schedules
the threads in non-preemptive way (which doesn't require unportable
facilities like <CODE>SIGVTALRM</CODE>). On the other hand, this way not all fancy threading features can be
implemented. Nevertheless the available facilities are enough to provide a
robust and full-featured threading system.
<DT><P><STRONG>o</STRONG><DD>
<STRONG>Pth increases the responsiveness and concurrency of an event-driven
application, but NOT the concurrency of number-crunching applications</STRONG>.
<P>
The reason is the non-preemptive scheduling. Number-crunching applications usually require preemptive scheduling to achieve concurrency because of their long
<FONT SIZE="-1">CPU</FONT> bursts. For them, non-preemptive scheduling (even together with explicit yielding) provides only the old concept of `coroutines'. On the other hand, event driven applications benefit greatly from non-preemptive scheduling. They have only short
<FONT SIZE="-1">CPU</FONT> bursts and lots of events to wait on, and this way run faster under non-preemptive scheduling because no unnecessary context switching occurs, as it is the case for preemptive scheduling. That's why
 <STRONG>Pth</STRONG>
is mainly intended for server type applications, although there is no
technical restriction.
<DT><P><STRONG>o</STRONG><DD>
<STRONG>Pth requires thread-safe functions, but NOT reentrant functions</STRONG>.
<P>
This nice fact exists again because of the nature of non-preemptive
scheduling, where a function isn't interrupted and this way cannot be
reentered before it returned. This is a great portability benefit, because
thread-safety can be achieved more easily than reentrance possibility.
Especially this means that under <STRONG>Pth</STRONG> more existing third-party libraries can be used without side-effects than
its the case for other threading systems.
<DT><P><STRONG>o</STRONG><DD>
<STRONG>Pth doesn't require any kernel support, but can NOT
benefit from multiprocessor machines</STRONG>.
<P>
This means that <STRONG>Pth</STRONG> runs on almost all Unix kernels, because the kernel does not need to be
aware of the <STRONG>Pth</STRONG> threads (because they are implemented entirely in user-space). On the other
hand, it cannot benefit from the existence of multiprocessors, because for
this, kernel support would be needed. In practice, this is no problem,
because multiprocessor systems are rare, and portability is almost more
important than highest concurrency.
</DL>
<P>
<H2><A NAME="The_life_cycle_of_a_thread"><font face="Arial,Helvetica">The life cycle of a thread</A></H2></font>
<P>
To understand the <STRONG>Pth</STRONG> Application Programming Interface
<FONT SIZE="-1">(API),</FONT> it helps to first understand the life cycle of
a thread in the <STRONG>Pth</STRONG>
threading system. It can be illustrated with the following directed graph:
<P>
<PRE>             NEW
              |
              V
      +---&gt; READY ---+
      |       ^      |
      |       |      V
   WAITING &lt;--+-- RUNNING
                     |
      :              V
   SUSPENDED       DEAD
</PRE>
<P>
When a new thread is created, it is moved into the <STRONG>NEW</STRONG> queue of the scheduler. On the next dispatching for this thread, the
scheduler picks it up from there and moves it to the <STRONG>READY</STRONG> queue. This is a queue containing all threads which want to perform a
<FONT SIZE="-1">CPU</FONT> burst. There they are queued in priority order. On
each dispatching step, the scheduler always removes the thread with the
highest priority only. It then increases the priority of all remaining
threads by 1, to prevent them from `starving'.
<P>
The thread which was removed from the <STRONG>READY</STRONG> queue is the new
<STRONG>RUNNING</STRONG> thread (there is always just one <STRONG>RUNNING</STRONG> thread, of course). The <STRONG>RUNNING</STRONG> thread is assigned execution control. After this thread yields execution
(either explicitly by yielding excution or implicitly by calling a function
which would block) there are three possibilities: Either it has terminated,
then it is moved to the <STRONG>DEAD</STRONG>
queue, or it has events on which it wants to wait, then it is moved into
the <STRONG>WAITING</STRONG> queue. Else it is assumed it wants to perform more
<FONT SIZE="-1">CPU</FONT> bursts and immediately enters the <STRONG>READY</STRONG> queue again.
<P>
Before the next thread is taken out of the <STRONG>READY</STRONG> queue, the
<STRONG>WAITING</STRONG> queue is checked for pending events. If one or more events occurred, the
threads that are waiting on them are immediately moved to the <STRONG>READY</STRONG> queue.
<P>
The purpose of the <STRONG>NEW</STRONG> queue has to do with the fact that in <STRONG>Pth</STRONG>
a thread never directly switches to another thread.
<FONT SIZE="-1">A</FONT> thread always yields execution to the scheduler and
the scheduler dispatches to the next thread. So a freshly spawned thread
has to be kept somewhere until the scheduler gets a chance to pick it up
for scheduling. That is for what the <STRONG>NEW</STRONG> queue is for.
<P>
The purpose of the <STRONG>DEAD</STRONG> queue is to support thread joining. When a thread is marked to be
unjoinable, it is directly kicked out of the system after it terminated.
But when it is joinable, it enters the
<STRONG>DEAD</STRONG> queue. There it remains until another thread joins it.
<P>
Finally, there is a special separated queue named <STRONG>SUSPENDED</STRONG>, to where threads can be manually moved from the <STRONG>NEW</STRONG>, <STRONG>READY</STRONG> or <STRONG>WAITING</STRONG>
queues by the application. The purpose of this special queue is to
temporarily absorb suspended threads until they are again resumed by the
application. Suspended threads do not cost scheduling or event handling
resources, because they are temporarily completely out of the scheduler's
scope. If a thread is resumed, it is moved back to the queue from where it
originally came and this way again enters the schedulers scope.
<P>
<H1><A NAME="APPLICATION_PROGRAMMING_INTERFAC"><font face="Arial,Helvetica">APPLICATION PROGRAMMING INTERFACE (API)</A></H1></font>
<P>
In the following the <STRONG>Pth</STRONG>  <EM>Application Programming Interface</EM>
<FONT SIZE="-1">(API)</FONT> is discussed in detail. With the knowledge given above, it should be now easy to understand how to program threads with this
<FONT SIZE="-1">API.</FONT> In good Unix tradition,
 <STRONG>Pth</STRONG> functions use special return values (<CODE>NULL</CODE>
in pointer context, <CODE>FALSE</CODE> in boolean context and <CODE>-1</CODE> in integer context) to indicate an error condition and set (or pass
through) the
<CODE>errno</CODE> system variable to pass more details about the error to the caller.
<P>
<H2><A NAME="Global_Library_Management"><font face="Arial,Helvetica">Global Library Management</A></H2></font>
<P>
The following functions act on the library as a whole. They are used to
initialize and shutdown the scheduler and fetch information from it.
<DL>
<DT><P><STRONG><A NAME="item_int">int pth_init(void);</A></STRONG><DD>
This initializes the <STRONG>Pth</STRONG> library. It has to be the first <STRONG>Pth</STRONG>
<FONT SIZE="-1">API</FONT> function call in an application, and is mandatory.
It's usually done at the begin of the <CODE>main()</CODE> function of the
application. This implicitly spawns the internal scheduler thread and
transforms the single execution unit of the current process into a thread
(the `main' thread). It returns <CODE>TRUE</CODE> on success and <CODE>FALSE</CODE> on error.
<DT><P><STRONG>int pth_kill(void);</STRONG><DD>
This kills the <STRONG>Pth</STRONG> library. It should be the last <STRONG>Pth</STRONG>
<FONT SIZE="-1">API</FONT> function call in an application, but is not really
required. It's usually done at the end of the main function of the
application. At least, it has to be called from within the main thread. It
implicitly kills all threads and transforms back the calling thread into
the single execution unit of the underlying process. The usual way to
terminate a <STRONG>Pth</STRONG> application is either a simple `<CODE>pth_exit(0);</CODE>' in the main thread (which waits for all other threads to terminate, kills
the threading system and then terminates the process) or a `<CODE>pth_kill(); exit(0)</CODE>' (which immediately kills the threading system and terminates the
process). The <CODE>pth_kill()</CODE> return immediately with a return code
of <CODE>FALSE</CODE> if it is called not from within the main thread. Else kills the threading
system and returns <CODE>TRUE</CODE>.
<DT><P><STRONG><A NAME="item_long">long pth_ctrl(unsigned long query, ...);</A></STRONG><DD>
This is a generalized query/control function for the <STRONG>Pth</STRONG> library. The argument <EM>query</EM> is a bitmask formed out of one or more <CODE>PTH_CTRL_</CODE><EM>XXXX</EM>
queries. Currently the following queries are supported:
<DL>
<DT><P><STRONG><A NAME="item_PTH_CTRL_GETTHREADS">PTH_CTRL_GETTHREADS</A></STRONG><DD>
This returns the total number of threads currently in existence. This query
actually is formed out of the combination of queries for threads in a
particular state, i.e., the <A HREF="#item_PTH_CTRL_GETTHREADS">PTH_CTRL_GETTHREADS</A> query is equal to the OR-combination of all the following specialized
queries:
<P>
<CODE>PTH_CTRL_GETTHREADS_NEW</CODE> for the number of threads in the new queue (threads created via
<CODE>pth_spawn(3)</CODE> but still not scheduled once), <CODE>PTH_CTRL_GETTHREADS_READY</CODE> for the number of threads in the ready queue (threads who want to do
<FONT SIZE="-1">CPU</FONT> bursts),
<CODE>PTH_CTRL_GETTHREADS_RUNNING</CODE> for the number of running threads (always just one thread!), <CODE>PTH_CTRL_GETTHREADS_WAITING</CODE> for the number of threads in the waiting queue (threads waiting for
events), <CODE>PTH_CTRL_GETTHREADS_SUSPENDED</CODE> for the number of threads in the suspended queue (threads waiting to be
resumed) and
<CODE>PTH_CTRL_GETTHREADS_DEAD</CODE> for the number of threads in the new queue (terminated threads waiting for
a join).
<DT><P><STRONG><A NAME="item_PTH_CTRL_GETAVLOAD">PTH_CTRL_GETAVLOAD</A></STRONG><DD>
This requires a second argument of type `<CODE>float *</CODE>' (pointer to a floating point variable). It stores a floating point value describing the exponential averaged load of the scheduler in this variable. The load is a function from the number of threads in the ready queue of the schedulers dispatching unit. So a load around 1.0 means there is only one ready thread (the standard situation when the application has no high load).
<FONT SIZE="-1">A</FONT> higher load value means there a more threads ready who want to do
<FONT SIZE="-1">CPU</FONT> bursts. The average load value updates once per second only. The return value for this query is always 0.
<DT><P><STRONG><A NAME="item_PTH_CTRL_GETPRIO">PTH_CTRL_GETPRIO</A></STRONG><DD>
This requires a second argument of type `<A HREF="#item_pth_t">pth_t</A>' which identifies a thread. It returns the priority (ranging from <CODE>PTH_PRIO_MIN</CODE> to
<CODE>PTH_PRIO_MAX</CODE>) of the given thread.
<DT><P><STRONG><A NAME="item_PTH_CTRL_GETNAME">PTH_CTRL_GETNAME</A></STRONG><DD>
This requires a second argument of type `<A HREF="#item_pth_t">pth_t</A>' which identifies a thread. It returns the name of the given thread, i.e.,
the return value of <CODE>pth_ctrl(3)</CODE> should be casted to a `<CODE>char *</CODE>'.
<DT><P><STRONG><A NAME="item_PTH_CTRL_DUMPSTATE">PTH_CTRL_DUMPSTATE</A></STRONG><DD>
This requires a second argument of type `<CODE>FILE *</CODE>' to which a summary of the internal <STRONG>Pth</STRONG> library state is written to. The main information which is currently
written out is the current state of the thread pool.
</DL>
<P>
The function returns <CODE>-1</CODE> on error.
<DT><P><STRONG>long pth_version(void);</STRONG><DD>
This function returns a hex-value `0x<EM>V</EM><EM>RR</EM><EM>T</EM><EM>LL</EM>' which describes the current <STRONG>Pth</STRONG> library version. <EM>V</EM> is the version, <EM>RR</EM> the revisions,
<EM>LL</EM> the level and <EM>T</EM> the type of the level (alphalevel=0, betalevel=1, patchlevel=2, etc). For
instance <STRONG>Pth</STRONG> version 1.0b1 is encoded as 0x100101. The reason for this unusual mapping
is that this way the version number is steadily <EM>increasing</EM>. The same value is also available under compile time as
<CODE>PTH_VERSION</CODE>.
</DL>
<P>
<H2><A NAME="Thread_Attribute_Handling"><font face="Arial,Helvetica">Thread Attribute Handling</A></H2></font>
<P>
Attribute objects are used in <STRONG>Pth</STRONG> for two things: First stand-alone/unbound attribute objects are used to
store attributes for to be spawned threads. Bounded attribute objects are
used to modify attributes of already existing threads. The following
attribute fields exists in attribute objects:
<DL>
<DT><P><STRONG><A NAME="item_PTH_ATTR_PRIO">PTH_ATTR_PRIO (read-write) [int]</A></STRONG><DD>
Thread Priority between <CODE>PTH_PRIO_MIN</CODE> and <CODE>PTH_PRIO_MAX</CODE>. The default is <CODE>PTH_PRIO_STD</CODE>.
<DT><P><STRONG><A NAME="item_PTH_ATTR_NAME">PTH_ATTR_NAME (read-write) [char *]</A></STRONG><DD>
Name of thread (up to 40 characters are stored only), mainly for debugging
purposes.
<DT><P><STRONG><A NAME="item_PTH_ATTR_JOINABLE">PTH_ATTR_JOINABLE (read-write&gt; [int]</A></STRONG><DD>
The thread detachment type, <CODE>TRUE</CODE> indicates a joinable thread, <CODE>FALSE</CODE>
indicates a detached thread. When a the is detached after termination it is
immediately kicked out of the system instead of inserted into the dead
queue.
<DT><P><STRONG><A NAME="item_PTH_ATTR_CANCEL_STATE">PTH_ATTR_CANCEL_STATE (read-write) [unsigned int]</A></STRONG><DD>
The thread cancellation state, i.e., a combination of <CODE>PTH_CANCEL_ENABLE</CODE> or
<CODE>PTH_CANCEL_DISABLE</CODE> and <CODE>PTH_CANCEL_DEFERRED</CODE> or
<CODE>PTH_CANCEL_ASYNCHRONOUS</CODE>.
<DT><P><STRONG><A NAME="item_PTH_ATTR_STACK_SIZE">PTH_ATTR_STACK_SIZE (read-write) [unsigned int]</A></STRONG><DD>
The thread stack size in bytes. Use lower values than 64
<FONT SIZE="-1">KB</FONT> with great care!
<DT><P><STRONG><A NAME="item_PTH_ATTR_STACK_ADDR">PTH_ATTR_STACK_ADDR (read-write) [char *]</A></STRONG><DD>
<FONT SIZE="-1">A</FONT> pointer to the lower address of a chunk of
<CODE>malloc(3)'ed</CODE> memory for the stack.
<DT><P><STRONG><A NAME="item_PTH_ATTR_TIME_SPAWN">PTH_ATTR_TIME_SPAWN (read-only) [pth_time_t]</A></STRONG><DD>
The time when the thread was spawned. This can be queried only when the
attribute object is bound to a thread.
<DT><P><STRONG><A NAME="item_PTH_ATTR_TIME_LAST">PTH_ATTR_TIME_LAST (read-only) [pth_time_t]</A></STRONG><DD>
The time when the thread was last dispatched. This can be queried only when
the attribute object is bound to a thread.
<DT><P><STRONG><A NAME="item_PTH_ATTR_TIME_RAN">PTH_ATTR_TIME_RAN (read-only) [pth_time_t]</A></STRONG><DD>
The total time the thread was running. This can be queried only when the
attribute object is bound to a thread.
<DT><P><STRONG><A NAME="item_PTH_ATTR_START_FUNC">PTH_ATTR_START_FUNC (read-only) [void *(*)(void *)]</A></STRONG><DD>
The thread start function. This can be queried only when the attribute
object is bound to a thread.
<DT><P><STRONG><A NAME="item_PTH_ATTR_START_ARG">PTH_ATTR_START_ARG (read-only) [void *]</A></STRONG><DD>
The thread start argument. This can be queried only when the attribute
object is bound to a thread.
<DT><P><STRONG><A NAME="item_PTH_ATTR_STATE">PTH_ATTR_STATE (read-only) [pth_state_t]</A></STRONG><DD>
The scheduling state of the thread, i.e., either <CODE>PTH_STATE_NEW</CODE>,
<CODE>PTH_STATE_READY</CODE>, <CODE>PTH_STATE_WAITING</CODE>, or <CODE>PTH_STATE_DEAD</CODE>
This can be queried only when the attribute object is bound to a thread.
<DT><P><STRONG><A NAME="item_PTH_ATTR_EVENTS">PTH_ATTR_EVENTS (read-only) [pth_event_t]</A></STRONG><DD>
The event ring the thread is waiting for. This can be queried only when the
attribute object is bound to a thread.
<DT><P><STRONG><A NAME="item_PTH_ATTR_BOUND">PTH_ATTR_BOUND (read-only) [int]</A></STRONG><DD>
Whether the attribute object is bound (<CODE>TRUE</CODE>) to a thread or not (<CODE>FALSE</CODE>).
</DL>
<P>
The following
<FONT SIZE="-1">API</FONT> functions exists to handle the attribute objects:
<DL>
<DT><P><STRONG><A NAME="item_pth_attr_t">pth_attr_t pth_attr_of(pth_t tid);</A></STRONG><DD>
This returns a new attribute object <EM>bound</EM> to thread <EM>tid</EM>. Any queries on this object directly fetch attributes from <EM>tid</EM>. And attribute modifications directly change <EM>tid</EM>. Use such attribute objects to modify existing threads.
<DT><P><STRONG>pth_attr_t pth_attr_new(void);</STRONG><DD>
This returns a new <EM>unbound</EM> attribute object. An implicit <CODE>pth_attr_init()</CODE> is done on it.
Any queries on this object just fetch stored attributes from it. And
attribute modifications just change the stored attributes. Use such
attribute objects to pre-configure attributes for to be spawned threads.
<DT><P><STRONG>int pth_attr_init(pth_attr_t attr);</STRONG><DD>
This initializes an attribute object <EM>attr</EM> to the default values:
<A HREF="#item_PTH_ATTR_PRIO">PTH_ATTR_PRIO</A> := <CODE>PTH_PRIO_STD</CODE>, <A HREF="#item_PTH_ATTR_NAME">PTH_ATTR_NAME</A> := `<CODE>unknown</CODE>',
<A HREF="#item_PTH_ATTR_JOINABLE">PTH_ATTR_JOINABLE</A> := <CODE>TRUE</CODE>, <CODE>PTH_ATTR_CANCELSTATE</CODE> :=
<CODE>PTH_CANCEL_DEFAULT</CODE>, <A HREF="#item_PTH_ATTR_STACK_SIZE">PTH_ATTR_STACK_SIZE</A> := 64*1024 and
<A HREF="#item_PTH_ATTR_STACK_ADDR">PTH_ATTR_STACK_ADDR</A> := <CODE>NULL</CODE>. All other <CODE>PTH_ATTR_*</CODE> attributes are read-only attributes and don't receive default values in <EM>attr</EM>, because they exists only for bounded attribute objects.
<DT><P><STRONG>int pth_attr_set(pth_attr_t attr, int field, ...);</STRONG><DD>
This sets the attribute field <EM>field</EM> in <EM>attr</EM> to a value specified as an additional argument on the variable argument
list. The following attribute <EM>fields</EM> and argument pairs can be used:
<P>
<PRE> PTH_ATTR_PRIO           int
 PTH_ATTR_NAME           char *
 PTH_ATTR_JOINABLE       int
 PTH_ATTR_CANCEL_STATE   unsigned int
 PTH_ATTR_STACK_SIZE     unsigned int
 PTH_ATTR_STACK_ADDR     char *
</PRE>
<DT><P><STRONG>int pth_attr_get(pth_attr_t attr, int field, ...);</STRONG><DD>
This retrieves the attribute field <EM>field</EM> in <EM>attr</EM> and stores its value in the variable specified through a pointer in an
additional argument on the variable argument list. The following <EM>fields</EM> and argument pairs can be used:
<P>
<PRE> PTH_ATTR_PRIO           int *
 PTH_ATTR_NAME           char **
 PTH_ATTR_JOINABLE       int *
 PTH_ATTR_CANCEL_STATE   unsigned int *
 PTH_ATTR_STACK_SIZE     unsigned int *
 PTH_ATTR_STACK_ADDR     char **
 PTH_ATTR_TIME_SPAWN     pth_time_t *
 PTH_ATTR_TIME_LAST      pth_time_t *
 PTH_ATTR_TIME_RAN       pth_time_t *
 PTH_ATTR_START_FUNC     void *(**)(void *)
 PTH_ATTR_START_ARG      void **
 PTH_ATTR_STATE          pth_state_t *
 PTH_ATTR_EVENTS         pth_event_t *
 PTH_ATTR_BOUND          int *
</PRE>
<DT><P><STRONG>int pth_attr_destroy(pth_attr_t attr);</STRONG><DD>
This destroys a attribute object <EM>attr</EM>. After this <EM>attr</EM> is no longer a valid attribute object.
</DL>
<P>
<H2><A NAME="Thread_Control"><font face="Arial,Helvetica">Thread Control</A></H2></font>
<P>
The following functions control the threading itself and form the main
<FONT SIZE="-1">API</FONT> of the <STRONG>Pth</STRONG> library.
<DL>
<DT><P><STRONG><A NAME="item_pth_t">pth_t pth_spawn(pth_attr_t attr, void *(*entry)(void *), void *arg);</A></STRONG><DD>
This spawns a new thread with the attributes given in <EM>attr</EM> (or
<CODE>PTH_ATTR_DEFAULT</CODE> for default attributes - which means that thread priority, joinability and
cancel state are inherited from the current thread) with the starting point
at routine <EM>entry</EM>. This entry routine is called as `pth_exit(<EM>entry</EM>(<EM>arg</EM>))' inside the new thread unit, i.e., <EM>entry</EM>'s return value is fed to an implicit <CODE>pth_exit(3).</CODE> So the thread usually can exit by just returning. Nevertheless the thread can also exit explicitly at any time by calling <CODE>pth_exit(3).</CODE> But keep in mind that calling the
<FONT SIZE="-1">POSIX</FONT> function <CODE>exit(3)</CODE> still terminates the complete process and not just the current thread.
<P>
There is no <STRONG>Pth</STRONG>-internal limit on the number of threads one can spawn, except the limit
implied by the available virtual memory. <STRONG>Pth</STRONG> internally keeps track of thread in dynamic data structures. The function
returns
<CODE>NULL</CODE> on error.
<DT><P><STRONG>int pth_once(pth_once_t *ctrlvar, void (*func)(void *), void *arg);</STRONG><DD>
This is a convenience function which uses a control variable of type
<CODE>pth_once_t</CODE> to make sure a constructor function <EM>func</EM> is called only once as `<EM>func</EM>(<EM>arg</EM>)' in the system. In other words: Only the first call to
<CODE>pth_once(3)</CODE> by any thread in the system succeeds. The variable
referenced via
<EM>ctrlvar</EM> should be declared as `<CODE>pth_once_t</CODE>  <EM>variable-name</EM> =
<CODE>PTH_ONCE_INIT</CODE>;' before calling this function.
<DT><P><STRONG>pth_t pth_self(void);</STRONG><DD>
This just returns the unique thread handle of the currently running thread.
This handle itself has to be treated as an opaque entity by the
application. It's usually used as an argument to other functions who
require an argument of type <A HREF="#item_pth_t">pth_t</A>.
<DT><P><STRONG>int pth_suspend(pth_t tid);</STRONG><DD>
This suspends a thread <EM>tid</EM> until it is manually resumed again via <CODE>pth_resume(3).</CODE> For
this, the thread is moved to the <STRONG>SUSPENDED</STRONG> queue and this way is completely out of the scheduler's event handling and
thread dispatching scope. Suspending the current thread is not allowed. The
function returns <CODE>TRUE</CODE> on success and <CODE>FALSE</CODE> on errors.
<DT><P><STRONG>int pth_resume(pth_t tid);</STRONG><DD>
This function resumes a previously suspended thread <EM>tid</EM>, i.e. <EM>tid</EM>
has to stay on the <STRONG>SUSPENDED</STRONG> queue. The thread is moved to the
<STRONG>NEW</STRONG>, <STRONG>READY</STRONG> or <STRONG>WAITING</STRONG> queue (dependent on what its state was when the <CODE>pth_suspend(3)</CODE>
call were made) and this way again enters the event handling and thread
dispatching scope of the scheduler. The function returns <CODE>TRUE</CODE> on success and <CODE>FALSE</CODE> on errors.
<DT><P><STRONG>int pth_raise(pth_t tid, int sig)</STRONG><DD>
This function raises a signal for delivery to thread <EM>tid</EM> only. When one just raises a signal via <CODE>raise(3)</CODE> or
<CODE>kill(2),</CODE> its delivered to an arbitrary thread which has this
signal not blocked. With <CODE>pth_raise(3)</CODE> one can send a signal to
a thread and its guarantees that only this thread gets the signal
delivered. But keep in mind that nevertheless the signals <EM>action</EM> is still configured <EM>process</EM>-wide. When <EM>sig</EM> is 0 plain thread checking is performed, i.e., `<CODE>pth_raise(tid, 0)</CODE>' returns <CODE>TRUE</CODE> when thread <EM>tid</EM>
still exists in the <STRONG>PTH</STRONG> system but doesn't send any signal to it.
<DT><P><STRONG>int pth_yield(pth_t tid);</STRONG><DD>
This explicitly yields back the execution control to the scheduler thread. Usually the execution is implicitly transferred back to the scheduler when a thread waits for an event. But when a thread has to do larger
<FONT SIZE="-1">CPU</FONT> bursts, it can be reasonable to interrupt it explicitly by doing a few <CODE>pth_yield(3)</CODE> calls to give other threads a chance to execute, too. This obviously is the cooperating part of
 <STRONG>Pth</STRONG>.
<FONT SIZE="-1">A</FONT> thread <EM>has not</EM> to yield execution, of course. But when you want to program a server application with good response times the threads should be cooperative, i.e., when they should split their
<FONT SIZE="-1">CPU</FONT> bursts into smaller units with this call.
<P>
Usually one specifies <EM>tid</EM> as <CODE>NULL</CODE> to indicate to the scheduler that it can freely decide which thread to
dispatch next. But if one wants to indicate to the scheduler that a
particular thread should be favored on the next dispatching step, one can
specify this thread explicitly. This allows the usage of the old concept of <EM>coroutines</EM> where a thread/routine switches to a particular cooperating thread. If <EM>tid</EM> is not <CODE>NULL</CODE> and points to a <EM>new</EM>
or <EM>ready</EM> thread, it is guaranteed that this thread receives execution control on the
next dispatching step. If <EM>tid</EM> is in a different state (that is, not in <CODE>PTH_STATE_NEW</CODE> or <CODE>PTH_STATE_READY</CODE>) an error is reported.
<P>
The function usually returns <CODE>TRUE</CODE> for success and only <CODE>FALSE</CODE> (with
<CODE>errno</CODE> set to <CODE>EINVAL</CODE>) if <EM>tid</EM> specified and invalid or still not new or ready thread.
<DT><P><STRONG>int pth_nap(pth_time_t naptime);</STRONG><DD>
This functions suspends the execution of the current thread until <EM>naptime</EM>
is elapsed. <EM>naptime</EM> is of type <A HREF="#item_pth_time_t">pth_time_t</A> and this way has theoretically a resolution of one microsecond. In practice
you should neither rely on this nor that the thread is awakened exactly
after <EM>naptime</EM> has elapsed. It's only guarantees that the thread will sleep at least <EM>naptime</EM>. But because of the non-preemptive nature of <STRONG>Pth</STRONG> it can last longer (when another thread kept the
<FONT SIZE="-1">CPU</FONT> for a long time). Additionally the resolution is
dependent of the implementation of timers by the operating system and these
usually have only a resolution of 10 microseconds or larger. But usually
this isn't important for an application unless it tries to use this
facility for real time tasks.
<DT><P><STRONG>int pth_wait(pth_event_t ev);</STRONG><DD>
This is the link between the scheduler and the event facility (see below
for the various <CODE>pth_event_xxx()</CODE> functions). It's modeled like
<CODE>select(2),</CODE> i.e., one gives this function one or more events
(in the event ring specified by <EM>ev</EM>) on which the current thread wants to wait. The scheduler awakes the
thread when one ore more of them occurred after tagging them as occurred.
The <EM>ev</EM>
argument is a <EM>pointer</EM> to an event ring which isn't changed except for the tagging.
<CODE>pth_wait(3)</CODE> returns the number of occurred events and the
application can use <CODE>pth_event_occurred(3)</CODE> to test which events
occurred.
<DT><P><STRONG>int pth_cancel(pth_t tid);</STRONG><DD>
This cancels a thread <EM>tid</EM>. How the cancellation is done depends on the cancellation state of <EM>tid</EM> which the thread can configure itself. When its state is <CODE>PTH_CANCEL_DISABLE</CODE> a cancellation request is just made pending. When it is <CODE>PTH_CANCEL_ENABLE</CODE> it depends on the cancellation type what is performed. When its <CODE>PTH_CANCEL_DEFERRED</CODE> again the cancellation request is just made pending. But when its <CODE>PTH_CANCEL_ASYNCHRONOUS</CODE> the thread is immediately canceled before <CODE>pth_cancel(3)</CODE>
returns. The effect of a thread cancellation is equal to implicitly forcing
the thread to call `<CODE>pth_exit(PTH_CANCELED)</CODE>' at one of his cancellation points. In <STRONG>Pth</STRONG>
thread enter a cancellation point either explicitly via
<CODE>pth_cancel_point(3)</CODE> or implicitly by waiting for an event.
<DT><P><STRONG>int pth_abort(pth_t tid);</STRONG><DD>
This is the cruel way to cancel a thread <EM>tid</EM>. When it's already dead and waits to be joined it just joins it (via `<CODE>pth_join(</CODE><EM>tid</EM><CODE>, NULL)</CODE>') and this way kicks it out of the system. Else it forces the thread to be
not joinable and to allow asynchronous cancellation and then cancels it via
`<CODE>pth_cancel(</CODE><EM>tid</EM><CODE>)</CODE>'.
<DT><P><STRONG>int pth_join(pth_t tid, void **value);</STRONG><DD>
This joins the current thread with the thread specified via <EM>tid</EM>. It first suspends the current thread until the <EM>tid</EM> thread has terminated. Then it is awakened and stores the value of <EM>tid</EM>'s <CODE>pth_exit(3)</CODE> call into *<EM>value</EM> (if
<EM>value</EM> and not <CODE>NULL</CODE>) and returns to the caller.
<FONT SIZE="-1">A</FONT> thread can be joined only when it was <EM>not</EM> spawned with <CODE>PTH_FLAG_NOJOIN</CODE>.
<FONT SIZE="-1">A</FONT> thread can only be joined once, i.e., after the
<CODE>pth_join(3)</CODE> call the thread <EM>tid</EM> is removed from the system.
<DT><P><STRONG><A NAME="item_void">void pth_exit(void *value);</A></STRONG><DD>
This terminates the current thread. Whether it's immediately removed from
the system or inserted into the dead queue of the scheduler depends on its
join type which was specified at spawning time. When it was spawned with
<CODE>PTH_FLAG_NOJOIN</CODE> it's immediately removed and <EM>value</EM> is ignored. Else the thread is inserted into the dead queue and <EM>value</EM> remembered for a <CODE>pth_join(3)</CODE> call by another thread.
</DL>
<P>
<H2><A NAME="Utilities"><font face="Arial,Helvetica">Utilities</A></H2></font>
<P>
The following functions are utility functions.
<DL>
<DT><P><STRONG>int pth_fdmode(int fd, int mode);</STRONG><DD>
This switches the non-blocking mode flag on file descriptor <EM>fd</EM>. The argument <EM>mode</EM> can be <CODE>PTH_FDMODE_BLOCK</CODE> for switching <EM>fd</EM> into blocking
<FONT SIZE="-1">I/O</FONT> mode, <CODE>PTH_FDMODE_NONBLOCK</CODE> for switching <EM>fd</EM> into non-blocking
<FONT SIZE="-1">I/O</FONT> mode or <CODE>PTH_FDMODE_POLL</CODE> for just polling the current mode. The current mode is returned (either <CODE>PTH_FDMODE_BLOCK</CODE> or <CODE>PTH_FDMODE_NONBLOCK</CODE>) or
<CODE>PTH_FDMODE_ERROR</CODE> on error. Keep in mind that since <STRONG>Pth</STRONG> 1.1 there is no longer a requirement to manually switch a file descriptor
into non-blocking mode in order to use it. This is automatically done
temporarily inside <STRONG>Pth</STRONG>. Instead when you now switch a file descriptor explicitly into
non-blocking mode, <CODE>pth_read(3)</CODE> or <CODE>pth_write(3)</CODE>
will never block the current thread.
<DT><P><STRONG><A NAME="item_pth_time_t">pth_time_t pth_time(long sec, long usec);</A></STRONG><DD>
This is a constructor for a <A HREF="#item_pth_time_t">pth_time_t</A> structure which is a convenient function to avoid temporary structure
values. It returns a <EM>pth_time_t</EM>
structure which holds the absolute time value specified by <EM>sec</EM> and <EM>usec</EM>.
<DT><P><STRONG>pth_time_t pth_timeout(long sec, long usec);</STRONG><DD>
This is a constructor for a <A HREF="#item_pth_time_t">pth_time_t</A> structure which is a convenient function to avoid temporary structure
values. It returns a <EM>pth_time_t</EM>
structure which holds the absolute time value calculated by adding <EM>sec</EM> and
<EM>usec</EM> to the current time.
<DT><P><STRONG><A NAME="item_Sfdisc_t">Sfdisc_t *pth_sfiodisc(void);</A></STRONG><DD>
This functions is always available, but only reasonably usable when <STRONG>Pth</STRONG>
was built with <STRONG>Sfio</STRONG> support (<CODE>--with-sfio</CODE> option) and <CODE>PTH_EXT_SFIO</CODE> is then defined by <CODE>pth.h</CODE>. It is useful for applications which want to use the comprehensive <STRONG>Sfio</STRONG>
<FONT SIZE="-1">I/O</FONT> library with the <STRONG>Pth</STRONG> threading library. Then this function can be used to get an <STRONG>Sfio</STRONG> discipline structure (<A HREF="#item_Sfdisc_t">Sfdisc_t</A>) which can be pushed onto <STRONG>Sfio</STRONG> streams (<CODE>Sfio_t</CODE>) in order to let this stream use <CODE>pth_read(3)/pth_write(2)</CODE> instead of <CODE>read(2)/write(2).</CODE> The benefit is that this way
<FONT SIZE="-1">I/O</FONT> on the
 <STRONG>Sfio</STRONG> stream does only block the current thread instead of the whole process. The
application has to <CODE>free(3)</CODE> the <A HREF="#item_Sfdisc_t">Sfdisc_t</A>
structure when it is no longer needed. The Sfio package can be found at <A
HREF="http://www.research.att.com/sw/tools/sfio/.">http://www.research.att.com/sw/tools/sfio/.</A>
</DL>
<P>
<H2><A NAME="Cancellation_Management"><font face="Arial,Helvetica">Cancellation Management</A></H2></font>
<P>
<STRONG>Pth</STRONG> supports
<FONT SIZE="-1">POSIX</FONT> style thread cancellation via
<CODE>pth_cancel(3)</CODE> and the following two related functions:
<DL>
<DT><P><STRONG>void pth_cancel_state(int newstate, int *oldstate);</STRONG><DD>
This manages the cancellation state of the current thread. When <EM>oldstate</EM>
is not <CODE>NULL</CODE> the function stores the old cancellation state under the variable pointed
to by <EM>oldstate</EM>. When <EM>newstate</EM> is not <CODE>0</CODE> it sets the new cancellation state. <EM>oldstate</EM> is created before <EM>newstate</EM> is set.
<FONT SIZE="-1">A</FONT> state is a combination of <CODE>PTH_CANCEL_ENABLE</CODE> or <CODE>PTH_CANCEL_DISABLE</CODE> and
<CODE>PTH_CANCEL_DEFERRED</CODE> or <CODE>PTH_CANCEL_ASYNCHRONOUS</CODE>.
<CODE>PTH_CANCEL_ENABLE|PTH_CANCEL_DEFERRED</CODE> (or <CODE>PTH_CANCEL_DEFAULT</CODE>) is the default state where cancellation is possible but only at
cancellation points. Use <CODE>PTH_CANCEL_DISABLE</CODE> to complete disable cancellation for a thread and
<CODE>PTH_CANCEL_ASYNCHRONOUS</CODE> for allowing asynchronous cancellations, i.e., cancellations which can
happen at any time.
<DT><P><STRONG>void pth_cancel_point(void);</STRONG><DD>
This explicitly enter a cancellation point. When the current cancellation
state is <CODE>PTH_CANCEL_DISABLE</CODE> or no cancellation request is pending, this has no side-effect and returns
immediately. Else it calls `<CODE>pth_exit(PTH_CANCELED)</CODE>'.
</DL>
<P>
<H2><A NAME="Event_Handling"><font face="Arial,Helvetica">Event Handling</A></H2></font>
<P>
<STRONG>Pth</STRONG> has a very flexible event facility which is linked into the scheduler
through the <CODE>pth_wait(3)</CODE> function. The following functions
provide the handling of event rings.
<DL>
<DT><P><STRONG><A NAME="item_pth_event_t">pth_event_t pth_event(unsigned long spec, ...);</A></STRONG><DD>
This creates a new event ring consisting of a single initial event. The
type of the generated event is specified by <EM>spec</EM>. The following types are available:
<DL>
<DT><P><STRONG><A NAME="item_PTH_EVENT_FD">PTH_EVENT_FD</A></STRONG><DD>
This is a file descriptor event. One or more of <CODE>PTH_UNTIL_FD_READABLE</CODE>,
<CODE>PTH_UNTIL_FD_WRITEABLE</CODE> or <CODE>PTH_UNTIL_FD_EXECPTION</CODE> have to be OR-ed into
<EM>spec</EM> to specify on which state of the file descriptor you want to wait. The file
descriptor itself has to be given as an additional argument. Example: `<CODE>pth_event(PTH_EVENT_FD|PTH_UNTIL_FD_READABLE, fd)</CODE>'.
<DT><P><STRONG><A NAME="item_PTH_EVENT_SELECT">PTH_EVENT_SELECT</A></STRONG><DD>
This is a multiple file descriptor event modeled directly after the <CODE>select(2)</CODE> call (actually it is also used to implement <CODE>pth_select(3)</CODE> internally). It's a convenient way to wait for a large set of file descriptors at once and at each file descriptor for a different type of state. Additionally as a nice side-effect one receives the number of file descriptors which causes the event to be occurred (using
<FONT SIZE="-1">BSD</FONT> semantics, i.e., when a file descriptor occurred in two sets it's counted twice). The arguments correspond directly to the <CODE>select(2)</CODE> function arguments except that there is no timeout argument (because timeouts already can be handled via
 <A HREF="#item_PTH_EVENT_TIME">PTH_EVENT_TIME</A> events).
<P>
Example: `<CODE>pth_event(PTH_EVENT_SELECT, &amp;rc, nfd, rfds, wfds, efds)</CODE>' where
<CODE>rc</CODE> has to be of type `<A HREF="#item_int_">int *</A>', <CODE>nfd</CODE> has to be of type `<A HREF="#item_int">int</A>' and
<CODE>rfds</CODE>, <CODE>wfds</CODE> and <CODE>efds</CODE> have to be of type `<CODE>fd_set *</CODE>' (see <CODE>select(2)).</CODE> The number of occurred file descriptors are
stored in <CODE>rc</CODE>.
<DT><P><STRONG><A NAME="item_PTH_EVENT_SIGS">PTH_EVENT_SIGS</A></STRONG><DD>
This is a signal set event. The two additional arguments have to be a
pointer to a signal set (type `<CODE>sigset_t *</CODE>') and a pointer to a signal number variable (type `<A HREF="#item_int_">int *</A>'). This event waits until one of the signals in the signal set occurred.
As a result the occurred signal number is stored in the second additional
argument. Keep in mind that the <STRONG>Pth</STRONG> scheduler doesn't block signals automatically. So when you want to wait for
a signal with this event you've to block it via <CODE>sigprocmask(2)</CODE>
or it will be delivered without your notice. Example: `<CODE>sigemptyset(&amp;set); sigaddset(&amp;set, SIGINT);
pth_event(PTH_EVENT_SIG, &amp;set, &amp;sig);</CODE>'.
<DT><P><STRONG><A NAME="item_PTH_EVENT_TIME">PTH_EVENT_TIME</A></STRONG><DD>
This is a time point event. The additional argument has to be of type
<A HREF="#item_pth_time_t">pth_time_t</A> (usually on-the-fly generated via <CODE>pth_time(3)).</CODE> This events
waits until the specified time point has elapsed. Keep in mind that the
value is an absolute time point and not an offset. When you want to wait
for a specified amount of time, you've to add the current time to the
offset (usually on-the-fly achieved via <CODE>pth_timeout(3)).</CODE>
Example: `<CODE>pth_event(PTH_EVENT_TIME, pth_timeout(2,0))</CODE>'.
<DT><P><STRONG><A NAME="item_PTH_EVENT_MSG">PTH_EVENT_MSG</A></STRONG><DD>
This is a message port event. The additional argument has to be of type
<A HREF="#item_pth_msgport_t">pth_msgport_t</A>. This events waits until one or more messages were received on the
specified message port. Example: `<CODE>pth_event(PTH_EVENT_MSG, mp)</CODE>'.
<DT><P><STRONG><A NAME="item_PTH_EVENT_TID">PTH_EVENT_TID</A></STRONG><DD>
This is a thread event. The additional argument has to be of type <A HREF="#item_pth_t">pth_t</A>. One of <CODE>PTH_UNTIL_TID_NEW</CODE>, <CODE>PTH_UNTIL_TID_READY</CODE>, <CODE>PTH_UNTIL_TID_WAITING</CODE>
or <CODE>PTH_UNTIL_TID_DEAD</CODE> has to be OR-ed into <EM>spec</EM> to specify on which state of the thread you want to wait. Example: `<CODE>pth_event(PTH_EVENT_TID|PTH_UNTIL_TID_DEAD, tid)</CODE>'.
<DT><P><STRONG><A NAME="item_PTH_EVENT_FUNC">PTH_EVENT_FUNC</A></STRONG><DD>
This is a custom callback function event. Three additional arguments have
to be given with the following types: `<A HREF="#item_int">int (*)(void *)</A>', `<A HREF="#item_void_">void *</A>' and `<A HREF="#item_pth_time_t">pth_time_t</A>'. The first is a function pointer to a check function and the second
argument is a user-supplied context value which is passed to this function.
The scheduler calls this function on a regular basis (on his own scheduler
stack, so be very careful!) and the thread is kept sleeping while the
function returns
<CODE>FALSE</CODE>. Once it returned <CODE>TRUE</CODE> the thread will be awakend. The check interval is defined by the third
argument, i.e., the check function is polled again not until this amount of
time elapsed. Example: `<CODE>pth_event(PTH_EVENT_FUNC, func, arg, pth_time(0,500000))</CODE>'.
</DL>
<DT><P><STRONG><A NAME="item_unsigned">unsigned long pth_event_typeof(pth_event_t ev);</A></STRONG><DD>
This returns the type of event <EM>ev</EM>. It's a combination of the describing
<CODE>PTH_EVENT_XX</CODE> and <CODE>PTH_UNTIL_XX</CODE> value. This is especially useful to know which arguments have to be
supplied to the <CODE>pth_event_extract(3)</CODE> function.
<DT><P><STRONG>int pth_event_extract(pth_event_t ev, ...);</STRONG><DD>
When <CODE>pth_event(3)</CODE> is treated like <CODE>sprintf(3),</CODE>
then this function is <CODE>sscanf(3),</CODE> i.e., it is the inverse
operation of <CODE>pth_event(3).</CODE> This means that it can be used to
extract the ingredients of an event. The ingredients are stored into
variables which are given as pointers on the variable argument list. Which
pointers have to be present depends on the event type and has to be
determined by the caller before via <CODE>pth_event_typeof(3).</CODE>
<P>
To make it clear, when you constructed <EM>ev</EM> via `<CODE>ev =
pth_event(PTH_EVENT_FD, fd);</CODE>' you have to extract it via `<CODE>pth_event_extract(ev, &amp;fd)</CODE>', etc. For multiple arguments of an event the order of the pointer
arguments is the same as for <CODE>pth_event(3).</CODE> But always keep in
mind that you have to always supply <EM>pointers</EM> to <EM>variables</EM> and these variables have to be of the same type as the argument of
<CODE>pth_event(3)</CODE> required.
<DT><P><STRONG>pth_event_t pth_event_concat(pth_event_t ev, ...);</STRONG><DD>
This concatenates one or more additional event rings to the event ring <EM>ev</EM>
and returns <EM>ev</EM>. The end of the argument list has to be marked with a
<CODE>NULL</CODE> argument. Use this function to create real events rings out of the
single-event rings created by <CODE>pth_event(3).</CODE>
<DT><P><STRONG>pth_event_t pth_event_isolate(pth_event_t ev);</STRONG><DD>
This isolates the event <EM>ev</EM> from possibly appended events in the event ring. When in <EM>ev</EM> only one event exists, this returns <CODE>NULL</CODE>. When remaining events exists, they form a new event ring which is
returned.
<DT><P><STRONG>pth_event_t pth_event_walk(pth_event_t ev, int direction);</STRONG><DD>
This walks to the next (when <EM>direction</EM> is <CODE>PTH_WALK_NEXT</CODE>) or previews (when <EM>direction</EM> is <CODE>PTH_WALK_PREV</CODE>) event in the event ring <EM>ev</EM> and returns this new reached event. Additionally <CODE>PTH_UNTIL_OCCURRED</CODE> can be OR-ed into <EM>direction</EM> to walk to the next/previous occurred event in the ring <EM>ev</EM>.
<DT><P><STRONG>int pth_event_occurred(pth_event_t ev);</STRONG><DD>
This checks whether the event <EM>ev</EM> occurred. This is a fast operation because only a tag on <EM>ev</EM> is checked which was either set or still not set by the scheduler. In other
words: This doesn't check the event itself, it just checks the last
knowledge of the scheduler.
<DT><P><STRONG>int pth_event_free(pth_event_t ev, int mode);</STRONG><DD>
This deallocates the event <EM>ev</EM> (when <EM>mode</EM> is <CODE>PTH_FREE_THIS</CODE>) or all events appended to the event ring under <EM>ev</EM> (when <EM>mode</EM> is
<CODE>PTH_FREE_ALL</CODE>).
</DL>
<P>
<H2><A NAME="Key_Based_Storage"><font face="Arial,Helvetica">Key-Based Storage</A></H2></font>
<P>
The following functions provide thread-local storage through unique keys similar to the
<FONT SIZE="-1">POSIX</FONT>
 <STRONG>Pthread</STRONG>
<FONT SIZE="-1">API.</FONT> Use this for thread specific global data.
<DL>
<DT><P><STRONG>int pth_key_create(pth_key_t *key, void (*func)(void *));</STRONG><DD>
This created a new unique key and stores it in <EM>key</EM>. Additionally <EM>func</EM>
can specify a destructor function which is called on the current threads
termination with the <EM>key</EM>.
<DT><P><STRONG>int pth_key_delete(pth_key_t key);</STRONG><DD>
This explicitly destroys a key <EM>key</EM>.
<DT><P><STRONG>int pth_key_setdata(pth_key_t key, const void *value);</STRONG><DD>
This stores <EM>value</EM> under <EM>key</EM>.
<DT><P><STRONG>void *pth_key_getdata(pth_key_t key);</STRONG><DD>
This retrieves the value under <EM>key</EM>.
</DL>
<P>
<H2><A NAME="Message_Port_Communication"><font face="Arial,Helvetica">Message Port Communication</A></H2></font>
<P>
The following functions provide message ports which can be used for
efficient and flexible inter-thread communication.
<DL>
<DT><P><STRONG><A NAME="item_pth_msgport_t">pth_msgport_t pth_msgport_create(const char *name);</A></STRONG><DD>
This returns a pointer to a new message port with name <EM>name</EM>. The <EM>name</EM>
can be used by other threads via <CODE>pth_msgport_find(3)</CODE> to find
the message port in case they do not know directly the pointer to the
message port.
<DT><P><STRONG>void pth_msgport_destroy(pth_msgport_t mp);</STRONG><DD>
This destroys a message port <EM>mp</EM>. Before all pending messages on it are replied to their origin message
port.
<DT><P><STRONG>pth_msgport_t pth_msgport_find(const char *name);</STRONG><DD>
This finds a message port in the system by <EM>name</EM> and returns the pointer to it.
<DT><P><STRONG>int pth_msgport_pending(pth_msgport_t mp);</STRONG><DD>
This returns the number of pending messages on message port <EM>mp</EM>.
<DT><P><STRONG>int pth_msgport_put(pth_msgport_t mp, pth_message_t *m);</STRONG><DD>
This puts (or sends) a message <EM>m</EM> to message port <EM>mp</EM>.
<DT><P><STRONG><A NAME="item_pth_message_t">pth_message_t *pth_msgport_get(pth_msgport_t mp);</A></STRONG><DD>
This gets (or receives) the top message from message port <EM>mp</EM>. Incoming messages are always kept in a queue, so there can be more
pending messages, of course.
<DT><P><STRONG>int pth_msgport_reply(pth_message_t *m);</STRONG><DD>
This replies a message <EM>m</EM> to the message port of the sender.
</DL>
<P>
<H2><A NAME="Thread_Cleanups"><font face="Arial,Helvetica">Thread Cleanups</A></H2></font>
<P>
The following functions provide per-thread cleanup functions.
<DL>
<DT><P><STRONG>int pth_cleanup_push(void (*handler)(void *), void *arg);</STRONG><DD>
This pushes the routine <EM>handler</EM> onto the stack of cleanup routines for the current thread. These routines are called in
<FONT SIZE="-1">LIFO</FONT> order when the thread terminates.
<DT><P><STRONG>int pth_cleanup_pop(int execute);</STRONG><DD>
This pops the top-most routine from the stack of cleanup routines for the
current thread. When <EM>execute</EM> is <CODE>TRUE</CODE> the routine is additionally called.
</DL>
<P>
<H2><A NAME="Process_Forking"><font face="Arial,Helvetica">Process Forking</A></H2></font>
<P>
The following functions provide some special support for process forking
situations inside the threading environment.
<DL>
<DT><P><STRONG>int pth_atfork_push(void (*prepare)(void *), void (*)(void *parent), void (*)(void *child), void *arg);</STRONG><DD>
This function declares forking handlers to be called before and after
<CODE>pth_fork(3),</CODE> in the context of the thread that called
<CODE>pth_fork(3).</CODE> The
<EM>prepare</EM> handler is called before <CODE>fork(2)</CODE> processing commences. The
<EM>parent</EM> handler is called after <CODE>fork(2)</CODE> processing completes in the
parent process. The <EM>child</EM> handler is called after <CODE>fork(2)</CODE> processing completed in the
child process. If no handling is desired at one or more of these three
points, the corresponding handler can be given as <CODE>NULL</CODE>. Each handler is called with <EM>arg</EM> as the argument.
<P>
The order of calls to <CODE>pth_atfork_push(3)</CODE> is significant. The <EM>parent</EM> and
<EM>child</EM> handlers are called in the order in which they were established by calls to <CODE>pth_atfork_push(3),</CODE> i.e.,
<FONT SIZE="-1">FIFO.</FONT> The
 <EM>prepare</EM> fork handlers are called in the opposite order, i.e.,
<FONT SIZE="-1">LIFO.</FONT>
<DT><P><STRONG>int pth_atfork_pop(void);</STRONG><DD>
This removes the top-most handlers on the forking handler stack which were
established with the last <CODE>pth_atfork_push(3)</CODE> call. It returns <CODE>FALSE</CODE> when no more handlers couldn't be removed from the stack.
<DT><P><STRONG><A NAME="item_pid_t">pid_t pth_fork(void);</A></STRONG><DD>
This is a variant of <CODE>fork(2)</CODE> with the difference that the
current thread only is forked into a separate process, i.e., in the parent
process nothing changes while in the child process all threads are gone
except for the scheduler and the calling thread. When you really want to
duplicate all threads in the current process you should use
<CODE>fork(2)</CODE> directly. But this is usually not reasonable.
Additionally this function takes care of forking handlers as established by
<CODE>pth_fork_push(3).</CODE>
</DL>
<P>
<H2><A NAME="Synchronization"><font face="Arial,Helvetica">Synchronization</A></H2></font>
<P>
The following functions provide synchronization support via mutual
exclusion locks (<STRONG>mutex</STRONG>), read-write locks (<STRONG>rwlock</STRONG>), condition variables (<STRONG>cond</STRONG>) and barriers (<STRONG>barrier</STRONG>). Keep in mind that in a non-preemptive threading system like <STRONG>Pth</STRONG> this might sound unnecessary at the first look, because a thread isn't
interrupted by the system. Actually when you have a critical code section
which doesn't contain any <CODE>pth_xxx()</CODE> functions, you don't need
any mutex to protect it, of course.
<P>
But when your critical code section contains any <CODE>pth_xxx()</CODE>
function the chance is high that these temporarily switch to the scheduler.
And this way other threads can make progress and enter your critical code
section, too. This is especially true for critical code sections which
implicitly or explicitly use the event mechanism.
<DL>
<DT><P><STRONG>int pth_mutex_init(pth_mutex_t *mutex);</STRONG><DD>
This dynamically initializes a mutex variable of type `<CODE>pth_mutex_t</CODE>'. Alternatively one can also use static initialization via `<CODE>pth_mutex_t
mutex = PTH_MUTEX_INIT</CODE>'.
<DT><P><STRONG>int pth_mutex_acquire(pth_mutex_t *mutex, int try, pth_event_t ev);</STRONG><DD>
This acquires a mutex <EM>mutex</EM>. If the mutex is already locked by another thread, the current threads
execution is suspended until the mutex is unlocked again or additionally
the extra events in <EM>ev</EM> occurred (when <EM>ev</EM> is not
<CODE>NULL</CODE>). Recursive locking is explicitly supported, i.e., a thread is allowed to
acquire a mutex more than once before its released. But it then also has be
released the same number of times until the mutex is again lockable by
others. When <EM>try</EM> is <CODE>TRUE</CODE> this function never suspends execution. Instead it returns <CODE>FALSE</CODE> with <CODE>errno</CODE> set to <CODE>EBUSY</CODE>.
<DT><P><STRONG>int pth_mutex_release(pth_mutex_t *mutex);</STRONG><DD>
This decrements the recursion locking count on <EM>mutex</EM> and when it is zero it releases the mutex <EM>mutex</EM>.
<DT><P><STRONG>int pth_rwlock_init(pth_rwlock_t *rwlock);</STRONG><DD>
This dynamically initializes a read-write lock variable of type `<CODE>pth_rwlock_t</CODE>'. Alternatively one can also use static initialization via `<CODE>pth_rwlock_t rwlock = PTH_RWLOCK_INIT</CODE>'.
<DT><P><STRONG>int pth_rwlock_acquire(pth_rwlock_t *rwlock, int op, int try, pth_event_t ev);</STRONG><DD>
This acquires a read-only (when <EM>op</EM> is <CODE>PTH_RWLOCK_RD</CODE>) or a read-write (when <EM>op</EM> is <CODE>PTH_RWLOCK_RW</CODE>) lock <EM>rwlock</EM>. When the lock is only locked by other threads in read-only mode, the lock
succeeds. But when one thread holds a read-write lock, all locking attempts
suspend the current thread until this lock is released again. Additionally
in <EM>ev</EM> events can be given to let the locking timeout, etc. When <EM>try</EM> is <CODE>TRUE</CODE> this function never suspends execution. Instead it returns <CODE>FALSE</CODE> with <CODE>errno</CODE> set to <CODE>EBUSY</CODE>.
<DT><P><STRONG>int pth_rwlock_release(pth_rwlock_t *rwlock);</STRONG><DD>
This releases a previously acquired (read-only or read-write) lock.
<DT><P><STRONG>int pth_cond_init(pth_cond_t *cond);</STRONG><DD>
This dynamically initializes a condition variable variable of type `<CODE>pth_cond_t</CODE>'. Alternatively one can also use static initialization via `<CODE>pth_cond_t cond = PTH_COND_INIT</CODE>'.
<DT><P><STRONG>int pth_cond_await(pth_cond_t *cond, pth_mutex_t *mutex, pth_event_t ev);</STRONG><DD>
This awaits a condition situation. The caller has to follow the semantics of the
<FONT SIZE="-1">POSIX</FONT> condition variables:
 <EM>mutex</EM> has to be acquired before this function is called. The execution of the
current thread is then suspended either until the events in <EM>ev</EM> occurred (when <EM>ev</EM> is not <CODE>NULL</CODE>) or
<EM>cond</EM> was notified by another thread via <CODE>pth_cond_notify(3).</CODE> While
the thread is waiting, <EM>mutex</EM> is released. Before it returns <EM>mutex</EM> is reacquired.
<DT><P><STRONG>int pth_cond_notify(pth_cond_t *cond, int broadcast);</STRONG><DD>
This notified one or all threads which are waiting on <EM>cond</EM>. When
<EM>broadcast</EM> is <CODE>TRUE</CODE> all thread are notified, else only a single (unspecified) one.
<DT><P><STRONG>int pth_barrier_init(pth_barrier_t *barrier, int I&lt;threshold);</STRONG><DD>
This dynamically initializes a barrier variable of type `<CODE>pth_barrier_t</CODE>'. Alternatively one can also use static initialization via `<CODE>pth_barrier_t
barrier = PTH_BARRIER_INIT(</CODE><EM>threadhold</EM><CODE>)</CODE>'.
<DT><P><STRONG>int pth_barrier_reach(pth_barrier_t *barrier);</STRONG><DD>
This function reaches a barrier <EM>barrier</EM>. If this is the last thread (as specified by <EM>threshold</EM> on init of <EM>barrier</EM>) all threads are awakened. Else the current thread is suspended until the
last thread reached the barrier and this way awakes all threads. The
function returns (beside <CODE>FALSE</CODE> on error) the value <CODE>TRUE</CODE> for any thread which neither reached the barrier as the first nor the last
thread; <CODE>PTH_BARRIER_HEADLIGHT</CODE> for the thread which reached the barrier as the first thread and <CODE>PTH_BARRIER_TAILLIGHT</CODE> for the thread which reached the barrier as the last thread.
</DL>
<P>
<H2><A NAME="Generalized_POSIX_Replacement_AP"><font face="Arial,Helvetica">Generalized POSIX Replacement API</A></H2></font>
<P>
The following functions are generalized replacements functions for the
<FONT SIZE="-1">POSIX</FONT>
<FONT SIZE="-1">API,</FONT> i.e., they are similar to the functions under `
<STRONG>Standard POSIX
Replacement API</STRONG>' but all have an additional event argument which can be used for timeouts,
etc.
<DL>
<DT><P><STRONG>int pth_sigwait_ev(const sigset_t *set, int *sig, pth_event_t ev);</STRONG><DD>
This is equal to <CODE>pth_sigwait(3)</CODE> (see below), but has an
additional event argument <EM>ev</EM>. When <CODE>pth_sigwait(3)</CODE> suspends the current threads execution
it usually only uses the signal event on <EM>set</EM> to awake. With this function any number of extra events can be used to
awake the current thread (remember that
<EM>ev</EM> actually is an event <EM>ring</EM>).
<DT><P><STRONG>int pth_connect_ev(int s, const struct sockaddr *addr, socklen_t addrlen, pth_event_t ev);</STRONG><DD>
This is equal to <CODE>pth_connect(3)</CODE> (see below), but has an
additional event argument <EM>ev</EM>. When <CODE>pth_connect(3)</CODE> suspends the current threads execution it usually only uses the
<FONT SIZE="-1">I/O</FONT> event on
 <EM>fd</EM> to awake. With this function any number of extra events can be used to
awake the current thread (remember that
<EM>ev</EM> actually is an event <EM>ring</EM>).
<DT><P><STRONG>int pth_accept_ev(int s, struct sockaddr *addr, socklen_t *addrlen, pth_event_t ev);</STRONG><DD>
This is equal to <CODE>pth_accept(3)</CODE> (see below), but has an
additional event argument <EM>ev</EM>. When <CODE>pth_accept(3)</CODE> suspends the current threads execution it usually only uses the
<FONT SIZE="-1">I/O</FONT> event on
 <EM>fd</EM> to awake. With this function any number of extra events can be used to
awake the current thread (remember that
<EM>ev</EM> actually is an event <EM>ring</EM>).
<DT><P><STRONG>int pth_select_ev(int nfd, fd_set *rfds, fd_set *wfds, fd_set *efds, struct timeval *timeout, pth_event_t ev);</STRONG><DD>
This is equal to <CODE>pth_select(3)</CODE> (see below), but has an
additional event argument <EM>ev</EM>. When <CODE>pth_select(3)</CODE> suspends the current threads execution it usually only uses the
<FONT SIZE="-1">I/O</FONT> event on
 <EM>rfds</EM>, <EM>wfds</EM> and <EM>efds</EM> to awake. With this function any number of extra events can be used to
awake the current thread (remember that <EM>ev</EM> actually is an event <EM>ring</EM>).
<DT><P><STRONG>int pth_poll_ev(struct pollfd *fds, unsigned int nfd, int timeout, pth_event_t ev);</STRONG><DD>
This is equal to <CODE>pth_poll(3)</CODE> (see below), but has an
additional event argument
<EM>ev</EM>. When <CODE>pth_poll(3)</CODE> suspends the current threads execution it usually only uses the
<FONT SIZE="-1">I/O</FONT> event on
 <EM>fds</EM> to awake. With this function any number of extra events can be used to
awake the current thread (remember that <EM>ev</EM> actually is an event <EM>ring</EM>).
<DT><P><STRONG><A NAME="item_ssize_t">ssize_t pth_read_ev(int fd, void *buf, size_t nbytes, pth_event_t ev);</A></STRONG><DD>
This is equal to <CODE>pth_read(3)</CODE> (see below), but has an
additional event argument
<EM>ev</EM>. When <CODE>pth_read(3)</CODE> suspends the current threads execution it usually only uses the
<FONT SIZE="-1">I/O</FONT> event on
 <EM>fd</EM> to awake. With this function any number of extra events can be used to
awake the current thread (remember that <EM>ev</EM> actually is an event <EM>ring</EM>).
<DT><P><STRONG>ssize_t pth_readv_ev(int fd, const struct iovec *iovec, int iovcnt, pth_event_t ev);</STRONG><DD>
This is equal to <CODE>pth_readv(3)</CODE> (see below), but has an
additional event argument <EM>ev</EM>. When <CODE>pth_readv(3)</CODE> suspends the current threads execution it usually only uses the
<FONT SIZE="-1">I/O</FONT> event on
 <EM>fd</EM> to awake. With this function any number of extra events can be used to
awake the current thread (remember that
<EM>ev</EM> actually is an event <EM>ring</EM>).
<DT><P><STRONG>ssize_t pth_write_ev(int fd, const void *buf, size_t nbytes, pth_event_t ev);</STRONG><DD>
This is equal to <CODE>pth_write(3)</CODE> (see below), but has an
additional event argument
<EM>ev</EM>. When <CODE>pth_write(3)</CODE> suspends the current threads execution it usually only uses the
<FONT SIZE="-1">I/O</FONT> event on
 <EM>fd</EM> to awake. With this function any number of extra events can be used to
awake the current thread (remember that <EM>ev</EM>
actually is an event <EM>ring</EM>).
<DT><P><STRONG>ssize_t pth_writev_ev(int fd, const struct iovec *iovec, int iovcnt, pth_event_t ev);</STRONG><DD>
This is equal to <CODE>pth_writev(3)</CODE> (see below), but has an
additional event argument <EM>ev</EM>. When <CODE>pth_writev(3)</CODE> suspends the current threads execution it usually only uses the
<FONT SIZE="-1">I/O</FONT> event on
 <EM>fd</EM> to awake. With this function any number of extra events can be used to
awake the current thread (remember that
<EM>ev</EM> actually is an event <EM>ring</EM>).
</DL>
<P>
<H2><A NAME="Standard_POSIX_Replacement_API"><font face="Arial,Helvetica">Standard POSIX Replacement API</A></H2></font>
<P>
The following functions are standard replacements functions for the
<FONT SIZE="-1">POSIX</FONT>
<FONT SIZE="-1">API.</FONT> The difference is mainly that they suspend the current thread only instead of the whole process in case the file descriptors will block.
<DL>
<DT><P><STRONG>int pth_usleep(unsigned int usec);</STRONG><DD>
This is a variant of the
<FONT SIZE="-1">4.3BSD</FONT> <CODE>usleep(3)</CODE> function. It suspends
the current threads execution until <EM>usec</EM> microsecond (= <EM>usec</EM> * 1/1000000 sec) elapsed. The thread is guaranteed to not awakened before
this time, but because of the non-preemptive scheduling nature of <STRONG>Pth</STRONG>, it can be awakened later, of course. The difference between
<CODE>usleep(3)</CODE> and <CODE>pth_usleep(3)</CODE> is that that
<CODE>pth_usleep(3)</CODE> suspends only the execution of the current
thread and not the whole process.
<DT><P><STRONG>unsigned int pth_sleep(unsigned int sec);</STRONG><DD>
This is a variant of the
<FONT SIZE="-1">POSIX</FONT> <CODE>sleep(3)</CODE> function. It suspends the
current threads execution until <EM>sec</EM> seconds elapsed. The thread is guaranteed to not awakened before this time,
but because of the non-preemptive scheduling nature of <STRONG>Pth</STRONG>, it can be awakened later, of course. The difference between
<CODE>sleep(3)</CODE> and <CODE>pth_sleep(3)</CODE> is that that
<CODE>pth_sleep(3)</CODE> suspends only the execution of the current thread
and not the whole process.
<DT><P><STRONG>pid_t pth_waitpid(pid_t pid, int *status, int options);</STRONG><DD>
This is a variant of the
<FONT SIZE="-1">POSIX</FONT> <CODE>waitpid(2)</CODE> function. It suspends
the current threads execution until <EM>status</EM> information is available for a terminated child process <EM>pid</EM>. The difference between <CODE>waitpid(2)</CODE> and
<CODE>pth_waitpid(3)</CODE> is that that <CODE>pth_waitpid(3)</CODE>
suspends only the execution of the current thread and not the whole
process. For more details about the arguments and return code semantics see
<CODE>waitpid(2).</CODE>
<DT><P><STRONG>int pth_sigmask(int how, const sigset_t *set, sigset_t *oset)</STRONG><DD>
This is the <STRONG>Pth</STRONG> thread-related equivalent of
<FONT SIZE="-1">POSIX</FONT> <CODE>sigprocmask(2)</CODE> respectively
<CODE>pthread_sigmask(3).</CODE> The arguments <EM>how</EM>, <EM>set</EM> and <EM>oset</EM> directly relate to <CODE>sigprocmask(2),</CODE> because <STRONG>Pth</STRONG> internally just uses <CODE>sigprocmask(2)</CODE> here. So alternatively you
can also directly call <CODE>sigprocmask(2),</CODE> but for consistency
reasons you should use this function <CODE>pth_sigmask(3).</CODE>
<DT><P><STRONG>int pth_sigwait(const sigset_t *set, int *sig);</STRONG><DD>
This is a variant of the POSIX.1c <CODE>sigwait(3)</CODE> function. It
suspends the current threads execution until a signal in <EM>set</EM> occurred and stores the signal number in <EM>sig</EM>. The important point is that the signal is not delivered to a signal
handler. Instead it's caught by the scheduler only in order to awake the
<CODE>pth_sigwait()</CODE> call. The trick and noticeable point here is
that this way you get an asynchronous aware application that is written
completely synchronously. When you think about the problem of <EM>asynchronous safe</EM>
functions you should recognize that this is a great benefit.
<DT><P><STRONG>int pth_connect(int s, const struct sockaddr *addr, socklen_t addrlen);</STRONG><DD>
This is a variant of the
<FONT SIZE="-1">4.2BSD</FONT> <CODE>connect(2)</CODE> function. It
establishes a connection on a socket <EM>s</EM> to target specified in <EM>addr</EM> and <EM>addrlen</EM>. The difference between <CODE>connect(2)</CODE> and
<CODE>pth_connect(3)</CODE> is that that <CODE>pth_connect(3)</CODE>
suspends only the execution of the current thread and not the whole
process. For more details about the arguments and return code semantics see
<CODE>connect(2).</CODE>
<DT><P><STRONG>int pth_accept(int s, struct sockaddr *addr, socklen_t *addrlen);</STRONG><DD>
This is a variant of the
<FONT SIZE="-1">4.2BSD</FONT> <CODE>accept(2)</CODE> function. It accepts a
connection on a socket by extracting the first connection request on the
queue of pending connections, creating a new socket with the same
properties of <EM>s</EM> and allocates a new file descriptor for the socket (which is returned). The
difference between <CODE>accept(2)</CODE> and <CODE>pth_accept(3)</CODE> is
that that <CODE>pth_accept(3)</CODE> suspends only the execution of the
current thread and not the whole process. For more details about the
arguments and return code semantics see <CODE>accept(2).</CODE>
<DT><P><STRONG>int pth_select(int nfd, fd_set *rfds, fd_set *wfds, fd_set *efds, struct timeval *timeout);</STRONG><DD>
This is a variant of the
<FONT SIZE="-1">4.2BSD</FONT> <CODE>select(2)</CODE> function. It examines the
<FONT SIZE="-1">I/O</FONT> descriptor sets whose addresses are passed in
 <EM>rfds</EM>, <EM>wfds</EM>, and <EM>efds</EM> to see if some of their descriptors are ready for reading, are ready for
writing, or have an exceptional condition pending, respectively. For more
details about the arguments and return code semantics see
<CODE>select(2).</CODE>
<DT><P><STRONG>int pth_poll(struct pollfd *fds, unsigned int nfd, int timeout);</STRONG><DD>
This is a variant of the SysV <CODE>poll(2)</CODE> function. It examines the
<FONT SIZE="-1">I/O</FONT> descriptors which are passed in the array
 <EM>fds</EM> to see if some of them are ready for reading, are ready for writing, or
have an exceptional condition pending, respectively. For more details about
the arguments and return code semantics see <CODE>poll(2).</CODE>
<DT><P><STRONG>ssize_t pth_read(int fd, void *buf, size_t nbytes);</STRONG><DD>
This is a variant of the
<FONT SIZE="-1">POSIX</FONT> <CODE>read(2)</CODE> function. It reads up to <EM>nbytes</EM>
bytes into <EM>buf</EM> from file descriptor <EM>fd</EM>. The difference between <CODE>read(2)</CODE> and <CODE>pth_read(2)</CODE>
is that that <CODE>pth_read(2)</CODE> suspends execution of the current
thread until the file descriptor is ready for reading. For more details
about the arguments and return code semantics see <CODE>read(2).</CODE>
<DT><P><STRONG>ssize_t pth_readv(int fd, const struct iovec *iovec, int iovcnt);</STRONG><DD>
This is a variant of the
<FONT SIZE="-1">POSIX</FONT> <CODE>readv(2)</CODE> function. It reads data
from file descriptor <EM>fd</EM> into the first <EM>iovcnt</EM> rows of the <EM>iov</EM> vector. The difference between <CODE>readv(2)</CODE> and
<CODE>pth_readv(2)</CODE> is that that <CODE>pth_readv(2)</CODE> suspends
execution of the current thread until the file descriptor is ready for
reading. For more details about the arguments and return code semantics see
<CODE>readv(2).</CODE>
<DT><P><STRONG>ssize_t pth_write(int fd, const void *buf, size_t nbytes);</STRONG><DD>
This is a variant of the
<FONT SIZE="-1">POSIX</FONT> <CODE>write(2)</CODE> function. It writes <EM>nbytes</EM> bytes from <EM>buf</EM> to file descriptor <EM>fd</EM>. The difference between <CODE>write(2)</CODE> and
<CODE>pth_write(2)</CODE> is that that <CODE>pth_write(2)</CODE> suspends
execution of the current thread until the file descriptor is ready for
writing. For more details about the arguments and return code semantics see
<CODE>write(2).</CODE>
<DT><P><STRONG>ssize_t pth_writev(int fd, const struct iovec *iovec, int iovcnt);</STRONG><DD>
This is a variant of the
<FONT SIZE="-1">POSIX</FONT> <CODE>writev(2)</CODE> function. It writes data
to file descriptor <EM>fd</EM> from the first <EM>iovcnt</EM> rows of the <EM>iov</EM> vector. The difference between <CODE>writev(2)</CODE> and
<CODE>pth_writev(2)</CODE> is that that <CODE>pth_writev(2)</CODE> suspends
execution of the current thread until the file descriptor is ready for
reading. For more details about the arguments and return code semantics see
<CODE>writev(2).</CODE>
<DT><P><STRONG>ssize_t pth_pread(int fd, void *buf, size_t nbytes, off_t offset);</STRONG><DD>
This is a variant of the
<FONT SIZE="-1">POSIX</FONT> <CODE>pread(3)</CODE> function. It performs the
same action as a regular <CODE>read(2),</CODE> except that it reads from a
given position in the file without changing the file pointer. The first
three arguments are the same as for <CODE>pth_read(3)</CODE> with the
addition of a fourth argument <EM>offset</EM> for the desired position inside the file.
<DT><P><STRONG>ssize_t pth_pwrite(int fd, const void *buf, size_t nbytes, off_t offset);</STRONG><DD>
This is a variant of the
<FONT SIZE="-1">POSIX</FONT> <CODE>pwrite(3)</CODE> function. It performs the
same action as a regular <CODE>write(2),</CODE> except that it writes to a
given position in the file without changing the file pointer. The first
three arguments are the same as for <CODE>pth_write(3)</CODE> with the
addition of a fourth argument <EM>offset</EM> for the desired position inside the file.
</DL>
<P>
<H1><A NAME="EXAMPLE"><font face="Arial,Helvetica">EXAMPLE</A></H1></font>
<P>
The following example is a useless server which does nothing more than listening on
<FONT SIZE="-1">TCP</FONT> port 12345 and displaying the current time to the socket when a connection was established. For each incoming connection a thread is spawned. Additionally, to see more multithreading, a useless ticker thread runs simultaneously which outputs the current time to
<CODE>stderr</CODE> every 5 seconds. The example contains <EM>no</EM> error checking and is <EM>only</EM> intended to show you the look and feel of <STRONG>Pth</STRONG>.
<P>
<PRE> #include &lt;stdio.h&gt;
</PRE>
<P>
<PRE> #define PORT 12345
</PRE>
<P>
<PRE> /* the socket connection handler thread */
 static void *handler(void *_arg)
 {
     int fd = (int)_arg;
     time_t now;
     char *ct;
</PRE>
<P>
<PRE>     now = time(NULL);
     ct = ctime(&amp;now);
     pth_write(fd, ct, strlen(ct));
     close(fd);
     return NULL;
 }
</PRE>
<P>
<PRE> /* the stderr time ticker thread */
 static void *ticker(void *_arg)
 {
     time_t now;
     char *ct;
     float load;
</PRE>
<P>
<PRE>     for (;;) {
         pth_sleep(5);
         now = time(NULL);
         ct = ctime(&amp;now);
         ct[strlen(ct)-1] = '\0';
         pth_ctrl(PTH_CTRL_GETAVLOAD, &amp;load);
         printf(&quot;ticker: time: %s, average load: %.2f\n&quot;, ct, load);
     }
 }
</PRE>
<P>
<PRE> /* the main thread/procedure */
 int main(int argc, char *argv[])
 {
     pth_attr_t attr;
     struct sockaddr_in sar;
     struct protoent *pe;
     struct sockaddr_in peer_addr;
     int peer_len;
     int sa, sw;
     int port;
</PRE>
<P>
<PRE>     pth_init();
     signal(SIGPIPE, SIG_IGN);
</PRE>
<P>
<PRE>     attr = pth_attr_new();
     pth_attr_set(attr, PTH_ATTR_NAME, &quot;ticker&quot;);
     pth_attr_set(attr, PTH_ATTR_STACK_SIZE, 64*1024);
     pth_attr_set(attr, PTH_ATTR_JOINABLE, FALSE);
     pth_spawn(attr, ticker, NULL);
</PRE>
<P>
<PRE>     pe = getprotobyname(&quot;tcp&quot;);
     sa = socket(AF_INET, SOCK_STREAM, pe-&gt;p_proto);
     sar.sin_family = AF_INET;
     sar.sin_addr.s_addr = INADDR_ANY;
     sar.sin_port = htons(PORT);
     bind(sa, (struct sockaddr *)&amp;sar, sizeof(struct sockaddr_in));
     listen(sa, 10);
</PRE>
<P>
<PRE>     pth_attr_set(attr, PTH_ATTR_NAME, &quot;handler&quot;);
     for (;;) {
         peer_len = sizeof(peer_addr);
         sw = pth_accept(sa, (struct sockaddr *)&amp;peer_addr, &amp;peer_len);
         pth_spawn(attr, handler, (void *)sw);
     }
 }
</PRE>
<P>
<H1><A NAME="BUILD_ENVIRONMENTS"><font face="Arial,Helvetica">BUILD ENVIRONMENTS</A></H1></font>
<P>
In this section we will discuss the canonical ways to establish the build
environment for a <STRONG>Pth</STRONG> based program. The possibilities supported by <STRONG>Pth</STRONG>
range from very simple environments to rather complex ones.
<P>
<H2><A NAME="Manual_Build_Environment_Novice"><font face="Arial,Helvetica">Manual Build Environment (Novice)</A></H2></font>
<P>
As a first example, assume we have the above test program staying in the
source file <CODE>foo.c</CODE>. Then we can create a very simple build environment by just adding the
following <CODE>Makefile</CODE>:
<P>
<PRE> $ vi Makefile
 | CC      = cc
 | CFLAGS  = `pth-config --cflags`
 | LDFLAGS = `pth-config --ldflags`
 | LIBS    = `pth-config --libs`
 |
 | all: foo
 | foo: foo.o
 |     $(CC) $(LDFLAGS) -o foo foo.o $(LIBS)
 | foo.o: foo.c
 |     $(CC) $(CFLAGS) -c foo.c
 | clean:
 |     rm -f foo foo.o
</PRE>
<P>
This imports the necessary compiler and linker flags on-the-fly from the
<STRONG>Pth</STRONG> installation via its <CODE>pth-config</CODE> program. This approach is straight-foreward and works fine for small
projects.
<P>
<H2><A NAME="Autoconf_Build_Environment_Adva"><font face="Arial,Helvetica">Autoconf Build Environment (Advanced)</A></H2></font>
<P>
The previous approach is simple but unflexible. First, to speed up
building, it would be nice to not expand the compiler and linker flags
every time the compiler is started. Second, it would be useful to also be
able to build against an uninstalled <STRONG>Pth</STRONG>, that is, against a <STRONG>Pth</STRONG> source tree which was just configured and built, but not installed. Third,
it would be also useful to allow checking of the
<STRONG>Pth</STRONG> version to make sure it is at least a minimum required version. And
finally, it would be also great to make sure <STRONG>Pth</STRONG> works correctly by first performing some sanity compile and run-time checks. All this can be done if we use
<FONT SIZE="-1">GNU</FONT>
 <STRONG>autoconf</STRONG> and the <CODE>AC_CHECK_PTH</CODE> macro provided by <STRONG>Pth</STRONG>. For this, we establish the following three files:
<P>
First we again need the <CODE>Makefile</CODE>, but this time it contains <STRONG>autoconf</STRONG>
placeholders and additional cleanup targets. And we create it under the
name
<CODE>Makefile.in</CODE>, because it is now an input file for <STRONG>autoconf</STRONG>:
<P>
<PRE> $ vi Makefile.in
 | CC      = @CC@
 | CFLAGS  = @CFLAGS@
 | LDFLAGS = @LDFLAGS@
 | LIBS    = @LIBS@
 |
 | all: foo
 | foo: foo.o
 |     $(CC) $(LDFLAGS) -o foo foo.o $(LIBS)
 | foo.o: foo.c
 |     $(CC) $(CFLAGS) -c foo.c
 | clean:
 |     rm -f foo foo.o
 | distclean:
 |     rm -f foo foo.o
 |     rm -f config.log config.status config.cache
 |     rm -f Makefile
</PRE>
<P>
Because <STRONG>autoconf</STRONG> generates additional files, we added a canonical
<CODE>distclean</CODE> target which cleanups this, too. Second, we write a (minimalistic) <STRONG>autoconf</STRONG> script specification in a file
<CODE>configure.in</CODE>:
<P>
<PRE> $ vi configure.in
 | AC_INIT(Makefile.in)
 | AC_CHECK_PTH(1.3.0)
 | AC_OUTPUT(Makefile)
</PRE>
<P>
Then we let <STRONG>autoconf</STRONG>'s <CODE>aclocal</CODE> program generate for us an <CODE>aclocal.m4</CODE>
file containing <STRONG>Pth</STRONG>'s <CODE>AC_CHECK_PTH</CODE> macro. Then we generate the final
<CODE>configure</CODE> script out of this <CODE>aclocal.m4</CODE> file and the <CODE>configure.in</CODE>
file:
<P>
<PRE> $ aclocal --acdir=`pth-config --acdir`
 $ autoconf
</PRE>
<P>
After these steps, the working directory should look similar to this:
<P>
<PRE> $ ls -l
 -rw-r--r--  1 rse  users    176 Nov  3 11:11 Makefile.in
 -rw-r--r--  1 rse  users  15314 Nov  3 11:16 aclocal.m4
 -rwxr-xr-x  1 rse  users  52045 Nov  3 11:16 configure
 -rw-r--r--  1 rse  users     63 Nov  3 11:11 configure.in
 -rw-r--r--  1 rse  users   4227 Nov  3 11:11 foo.c
</PRE>
<P>
If we now run <CODE>configure</CODE> we get a correct <CODE>Makefile</CODE> which immediately can be used to build <CODE>foo</CODE> (assuming that <STRONG>Pth</STRONG> is already installed somewhere, so that <CODE>pth-config</CODE> is in <CODE>$PATH</CODE>):
<P>
<PRE> $ ./configure
 creating cache ./config.cache
 checking for gcc... gcc
 checking whether the C compiler (gcc   ) works... yes
 checking whether the C compiler (gcc   ) is a cross-compiler... no
 checking whether we are using GNU C... yes
 checking whether gcc accepts -g... yes
 checking how to run the C preprocessor... gcc -E
 checking for GNU Pth... version 1.3.0, installed under /usr/local
 updating cache ./config.cache
 creating ./config.status
 creating Makefile
 rse@en1:/e/gnu/pth/ac
 $ make
 gcc -g -O2 -I/usr/local/include -c foo.c
 gcc -L/usr/local/lib -o foo foo.o -lpth
</PRE>
<P>
If <STRONG>Pth</STRONG> is installed in non-standard locations or <CODE>pth-config</CODE>
is not in <CODE>$PATH</CODE>, one just has to drop the <CODE>configure</CODE> script a note about the location by running <CODE>configure</CODE> with the option
<CODE>--with-pth=</CODE><EM>dir</EM> (where <EM>dir</EM> is the argument which was used with the <CODE>--prefix</CODE> option when <STRONG>Pth</STRONG> was installed).
<P>
<H2><A NAME="Autoconf_Build_Environment_with_"><font face="Arial,Helvetica">Autoconf Build Environment with Local Copy of Pth (Expert)</A></H2></font>
<P>
Finally let us assume the <CODE>foo</CODE> program stays under either a <EM>GPL</EM> or
<EM>LGPL</EM> distribution license and we want to make it a stand-alone package for
easier distribution and installation. That is, we don't want that the
end-user first has to install <STRONG>Pth</STRONG> just to allow our <CODE>foo</CODE> package to compile. For this, it is a convinient practice to include the
required libraries (here <STRONG>Pth</STRONG>) into the source tree of the package (here <CODE>foo</CODE>).
<STRONG>Pth</STRONG> ships with all necessary support to allow us to easily achieve this
approach. Say, we want <STRONG>Pth</STRONG> in a subdirectory named <CODE>pth/</CODE> and this directory should be seamlessly integrated into the configuration
and build process of <CODE>foo</CODE>.
<P>
First we again start with the <CODE>Makefile.in</CODE>, but this time it is a more advanced version which supports subdirectory
movement:
<P>
<PRE> $ vi Makefile.in
 | CC      = @CC@
 | CFLAGS  = @CFLAGS@
 | LDFLAGS = @LDFLAGS@
 | LIBS    = @LIBS@
 |
 | SUBDIRS = pth
 |
 | all: subdirs_all foo
 |
 | subdirs_all:
 |     @$(MAKE) $(MFLAGS) subdirs TARGET=all
 | subdirs_clean:
 |     @$(MAKE) $(MFLAGS) subdirs TARGET=clean
 | subdirs_distclean:
 |     @$(MAKE) $(MFLAGS) subdirs TARGET=distclean
 | subdirs:
 |     @for subdir in $(SUBDIRS); do \
 |         echo &quot;===&gt; $$subdir ($(TARGET))&quot;; \
 |         (cd $$subdir; $(MAKE) $(MFLAGS) $(TARGET) || exit 1) || exit 1; \
 |         echo &quot;&lt;=== $$subdir&quot;; \
 |     done
 |
 | foo: foo.o
 |     $(CC) $(LDFLAGS) -o foo foo.o $(LIBS)
 | foo.o: foo.c
 |     $(CC) $(CFLAGS) -c foo.c
 |
 | clean: subdirs_clean
 |     rm -f foo foo.o
 | distclean: subdirs_distclean
 |     rm -f foo foo.o
 |     rm -f config.log config.status config.cache
 |     rm -f Makefile
</PRE>
<P>
Then we create a slightly different <STRONG>autoconf</STRONG> script <CODE>configure.in</CODE>:
<P>
<PRE> $ vi configure.in
 | AC_INIT(Makefile.in)
 | AC_CONFIG_AUX_DIR(pth)
 | AC_CHECK_PTH(1.3.0, subdir:pth --disable-tests)
 | AC_CONFIG_SUBDIRS(pth)
 | AC_OUTPUT(Makefile)
</PRE>
<P>
Here we provided a default value for <CODE>foo</CODE>'s <CODE>--with-pth</CODE> option as the second argument to <CODE>AC_CHECK_PTH</CODE> which indicates that <STRONG>Pth</STRONG> can be found in the subdirectory named <CODE>pth/</CODE>. Additionally we specified that the
<CODE>--disable-tests</CODE> option of <STRONG>Pth</STRONG> should be passed to the <CODE>pth/</CODE>
subdirectory, because we need only to build the <STRONG>Pth</STRONG> library itself. And we added a <CODE>AC_CONFIG_SUBDIR</CODE> call which indicates to <STRONG>autoconf</STRONG> that it should configure the <CODE>pth/</CODE> subdirectory, too. The <CODE>AC_CONFIG_AUX_DIR</CODE> directive was added just to make <STRONG>autoconf</STRONG> happy, because it wants to find a
<CODE>install.sh</CODE> or <CODE>shtool</CODE> script if <CODE>AC_CONFIG_SUBDIRS</CODE> is used.
<P>
Now we let <STRONG>autoconf</STRONG>'s <CODE>aclocal</CODE> program again generate for us an
<CODE>aclocal.m4</CODE> file with the contents of <STRONG>Pth</STRONG>'s <CODE>AC_CHECK_PTH</CODE> macro. Finally we generate the <CODE>configure</CODE> script out of this <CODE>aclocal.m4</CODE>
file and the <CODE>configure.in</CODE> file.
<P>
<PRE> $ aclocal --acdir=`pth-config --acdir`
 $ autoconf
</PRE>
<P>
Now we have to create the <CODE>pth/</CODE> subdirectory itself. For this, we extract the
<STRONG>Pth</STRONG> distribution to the <CODE>foo</CODE> source tree and just rename it to <CODE>pth/</CODE>:
<P>
<PRE> $ gunzip &lt;pth-X.Y.Z.tar.gz | tar xvf -
 $ mv pth-X.Y.Z pth
</PRE>
<P>
Optionally to reduce the size of the <CODE>pth/</CODE> subdirectory, we can strip down the <STRONG>Pth</STRONG> sources to a minimum with the <EM>striptease</EM> feature:
<P>
<PRE> $ cd pth
 $ ./configure
 $ make striptease
 $ cd ..
</PRE>
<P>
After this the source tree of <CODE>foo</CODE> should look similar to this:
<P>
<PRE> $ ls -l
 -rw-r--r--  1 rse  users    709 Nov  3 11:51 Makefile.in
 -rw-r--r--  1 rse  users  16431 Nov  3 12:20 aclocal.m4
 -rwxr-xr-x  1 rse  users  57403 Nov  3 12:21 configure
 -rw-r--r--  1 rse  users    129 Nov  3 12:21 configure.in
 -rw-r--r--  1 rse  users   4227 Nov  3 11:11 foo.c
 drwxr-xr-x  2 rse  users   3584 Nov  3 12:36 pth
 $ ls -l pth/
 -rw-rw-r--  1 rse  users   26344 Nov  1 20:12 COPYING
 -rw-rw-r--  1 rse  users    2042 Nov  3 12:36 Makefile.in
 -rw-rw-r--  1 rse  users    3967 Nov  1 19:48 README
 -rw-rw-r--  1 rse  users     340 Nov  3 12:36 README.1st
 -rw-rw-r--  1 rse  users   28719 Oct 31 17:06 config.guess
 -rw-rw-r--  1 rse  users   24274 Aug 18 13:31 config.sub
 -rwxrwxr-x  1 rse  users  155141 Nov  3 12:36 configure
 -rw-rw-r--  1 rse  users  162021 Nov  3 12:36 pth.c
 -rw-rw-r--  1 rse  users   18687 Nov  2 15:19 pth.h.in
 -rw-rw-r--  1 rse  users    5251 Oct 31 12:46 pth_acdef.h.in
 -rw-rw-r--  1 rse  users    2120 Nov  1 11:27 pth_acmac.h.in
 -rw-rw-r--  1 rse  users    2323 Nov  1 11:27 pth_p.h.in
 -rw-rw-r--  1 rse  users     946 Nov  1 11:27 pth_vers.c
 -rw-rw-r--  1 rse  users   26848 Nov  1 11:27 pthread.c
 -rw-rw-r--  1 rse  users   18772 Nov  1 11:27 pthread.h.in
 -rwxrwxr-x  1 rse  users   26188 Nov  3 12:36 shtool
</PRE>
<P>
Now when we configure and build the <CODE>foo</CODE> package it looks similar to this:
<P>
<PRE> $ ./configure
 creating cache ./config.cache
 checking for gcc... gcc
 checking whether the C compiler (gcc   ) works... yes
 checking whether the C compiler (gcc   ) is a cross-compiler... no
 checking whether we are using GNU C... yes
 checking whether gcc accepts -g... yes
 checking how to run the C preprocessor... gcc -E
 checking for GNU Pth... version 1.3.0, local under pth
 updating cache ./config.cache
 creating ./config.status
 creating Makefile
 configuring in pth
 running /bin/sh ./configure  --enable-subdir --enable-batch
 --disable-tests --cache-file=.././config.cache --srcdir=.
 loading cache .././config.cache
 checking for gcc... (cached) gcc
 checking whether the C compiler (gcc   ) works... yes
 checking whether the C compiler (gcc   ) is a cross-compiler... no
 [...]
 $ make
 ===&gt; pth (all)
 ./shtool scpp -o pth_p.h -t pth_p.h.in -Dcpp -Cintern -M '==#==' pth.c
 pth_vers.c
 gcc -c -I. -O2 -pipe pth.c
 gcc -c -I. -O2 -pipe pth_vers.c
 ar rc libpth.a pth.o pth_vers.o
 ranlib libpth.a
 &lt;=== pth
 gcc -g -O2 -Ipth -c foo.c
 gcc -Lpth -o foo foo.o -lpth
</PRE>
<P>
As you can see, <STRONG>autoconf</STRONG> now automatically configures the local (stripped down) copy of <STRONG>Pth</STRONG> in the subdirectory <CODE>pth/</CODE> and the
<CODE>Makefile</CODE> automatically builds the subdirectory, too.
<P>
<H1><A NAME="SYSTEM_CALL_WRAPPER_FACILITY"><font face="Arial,Helvetica">SYSTEM CALL WRAPPER FACILITY</A></H1></font>
<P>
<STRONG>Pth</STRONG> per default uses an explicit
<FONT SIZE="-1">API,</FONT> including the system calls. For instance you've
to explicitly use <CODE>pth_read(3)</CODE> when you need a thread-aware
<CODE>read(3)</CODE> and cannot expect that by just calling
<CODE>read(3)</CODE> only the current thread is blocked. Instead with the
standard <CODE>read(3)</CODE> call the whole process will be blocked. But
because for some applications (mainly those consisting of lots of
third-party stuff) this can be inconvenient. Here it's required that a call
to <CODE>read(3)</CODE> `magically' means <CODE>pth_read(3).</CODE> The
problem here is that such magic <STRONG>Pth</STRONG> cannot provide per default because it's not really portable. Nevertheless <STRONG>Pth</STRONG> provides a two step approach to solve this problem:
<P>
<H2><A NAME="Soft_System_Call_Mapping"><font face="Arial,Helvetica">Soft System Call Mapping</A></H2></font>
<P>
This variant is available on all platforms and can <EM>always</EM> be enabled by building <STRONG>Pth</STRONG> with <CODE>--enable-syscall-soft</CODE>. This then triggers some
<CODE>#define</CODE>'s in the <CODE>pth.h</CODE> header which map for instance <CODE>read(3)</CODE> to
<CODE>pth_read(3),</CODE> etc. Currently the following functions are
mapped: <CODE>fork(2),</CODE> <CODE>sleep(3),</CODE>
<CODE>sigwait(3),</CODE> <CODE>waitpid(2),</CODE> <CODE>select(2),</CODE>
<CODE>poll(2),</CODE> <CODE>connect(2),</CODE> <CODE>accept(2),</CODE>
<CODE>read(2),</CODE> <CODE>write(2).</CODE>
<P>
The drawback of this approach is just that really all source files of the
application where these function calls occur have to include
<CODE>pth.h</CODE>, of course. And this also means that existing libraries, including the
vendor's <STRONG>stdio</STRONG>, usually will still block the whole process if one of its
<FONT SIZE="-1">I/O</FONT> functions block.
<P>
<H2><A NAME="Hard_System_Call_Mapping"><font face="Arial,Helvetica">Hard System Call Mapping</A></H2></font>
<P>
This variant is available only on those platforms where the
<CODE>syscall(2)</CODE> function exists and there it can be enabled by
building <STRONG>Pth</STRONG> with
<CODE>--enable-syscall-hard</CODE>. This then builds wrapper functions (for instances <CODE>read(3))</CODE>
into the <STRONG>Pth</STRONG> library which internally call the real <STRONG>Pth</STRONG>
replacement functions (pth_read(3)). Currently the following functions are
mapped: <CODE>fork(2),</CODE> <CODE>sleep(3),</CODE>
<CODE>waitpid(2),</CODE> <CODE>select(2),</CODE> <CODE>poll(2),</CODE>
<CODE>connect(2),</CODE> <CODE>accept(2),</CODE> <CODE>read(2),</CODE>
<CODE>write(2).</CODE>
<P>
The drawback of this approach is that it depends on <CODE>syscall(2)</CODE> interface and prototype conflicts can occur while building the wrapper functions due to different function signatures in the vendor
<FONT SIZE="-1">C</FONT> header files. But the advantage of this mapping variant is that the source files of the application where these function calls occur have not to include
<CODE>pth.h</CODE> and that existing libraries, including the vendor's <STRONG>stdio</STRONG>, magically become thread-aware (and then block only the current thread).
<P>
<H1><A NAME="IMPLEMENTATION_NOTES"><font face="Arial,Helvetica">IMPLEMENTATION NOTES</A></H1></font>
<P>
<STRONG>Pth</STRONG> is very portable because it has only one part which perhaps has to be
ported to new platforms (the machine context initialization). But it is
written in a way which works on mostly all Unix platforms which support
<CODE>makecontext(2)</CODE> or at least <CODE>sigstack(2)</CODE> or
<CODE>sigaltstack(2)</CODE> [see
<CODE>pth_mctx.c</CODE> for details]. Any other <STRONG>Pth</STRONG> code is
<FONT SIZE="-1">POSIX</FONT> and
<FONT SIZE="-1">ANSI</FONT>
<FONT SIZE="-1">C</FONT> based only.
<P>
The context switching is done via either SUSv2 <CODE>makecontext(2)</CODE> or
<FONT SIZE="-1">POSIX</FONT> make[sig]setjmp(3) and [sig]longjmp(3). Here all
<FONT SIZE="-1">CPU</FONT> registers, the program counter and the stack pointer are switched. Additionally the
<STRONG>Pth</STRONG> dispatcher switches also the global Unix <CODE>errno</CODE> variable [see
<CODE>pth_mctx.c</CODE> for details] and the signal mask (either implicitly via
<CODE>sigsetjmp(3)</CODE> or in an emulated way via explicit
<CODE>setprocmask(2)</CODE> calls).
<P>
The <STRONG>Pth</STRONG> event manager is mainly <CODE>select(2)</CODE> and <CODE>gettimeofday(2)</CODE> based, i.e., the current time is fetched via <CODE>gettimeofday(2)</CODE> once per context switch for time calculations and all
<FONT SIZE="-1">I/O</FONT> events are implemented via a single central <CODE>select(2)</CODE> call [see
 <CODE>pth_sched.c</CODE> for details].
<P>
The thread control block management is done via virtual priority queues
without any additional data structure overhead. For this, the queue linkage
attributes are part of the thread control blocks and the queues are
actually implemented as rings with a selected element as the entry point
[see <CODE>pth_tcb.h</CODE> and <CODE>pth_pqueue.c</CODE> for details].
<P>
Most time critical code sections (especially the dispatcher and event manager) are speeded up by inlined functions (implemented as
<FONT SIZE="-1">ANSI</FONT>
<FONT SIZE="-1">C</FONT> pre-processor macros). Additionally any debugging code is
 <EM>completely</EM>
removed from the source when not built with <CODE>-DPTH_DEBUG</CODE> (see Autoconf
<CODE>--enable-debug</CODE> option), i.e., not only stub functions remain [see
<CODE>pth_debug.h</CODE> for details].
<P>
<H1><A NAME="RESTRICTIONS"><font face="Arial,Helvetica">RESTRICTIONS</A></H1></font>
<P>
<STRONG>Pth</STRONG> (intentionally) provides no replacements for non-thread-safe functions
(like <CODE>strtok(3)</CODE> which uses a static internal buffer) or
synchronous system functions (like <CODE>gethostbyname(3)</CODE> which
doesn't provide an asynchronous mode where it doesn't block). When you want
to use those functions in your server application together with threads,
you've to either link the application against special third-party libraries
(or for thread-safe/reentrant functions possibly against an existing <CODE>libc_r</CODE> of the platform vendor). For an asynchronous
<FONT SIZE="-1">DNS</FONT> resolver library use the
<FONT SIZE="-1">GNU</FONT>
 <STRONG>adns</STRONG> package from Ian Jackson ( see <A
HREF="http://www.gnu.org/software/adns/adns.html">http://www.gnu.org/software/adns/adns.html</A>
).
<P>
<H1><A NAME="HISTORY"><font face="Arial,Helvetica">HISTORY</A></H1></font>
<P>
The <STRONG>Pth</STRONG> library was designed and implemented between February and July 1999 by <EM>Ralf S. Engelschall</EM> after evaluating numerous (mostly preemptive) thread libraries and after
intensive discussions with
<EM>Peter Simons</EM>, <EM>Martin Kraemer</EM>, <EM>Lars Eilebrecht</EM> and <EM>Ralph
Babel</EM> related to an experimental (matrix based) non-preemptive
<FONT SIZE="-1">C++</FONT> scheduler class written by <EM>Peter Simons</EM>.
<P>
<STRONG>Pth</STRONG> was then implemented in order to combine the <EM>non-preemptive</EM>
approach of multithreading (which provides better portability and performance) with an
<FONT SIZE="-1">API</FONT> similar to the popular one found in
 <STRONG>Pthread</STRONG>
libraries (which provides easy programming).
<P>
So the essential idea of the non-preemptive approach was taken over from
<EM>Peter Simons</EM> scheduler. The priority based scheduling algorithm was suggested by <EM>Martin Kraemer</EM>. Some code inspiration also came from an experimental threading library (<STRONG>rsthreads</STRONG>) written by <EM>Robert
S. Thau</EM> for an ancient internal test version of the Apache webserver. The concept and
<FONT SIZE="-1">API</FONT> of message ports was borrowed from AmigaOS'
 <STRONG>Exec</STRONG>
subsystem. The concept and idea for the flexible event mechanism came from <EM>Paul Vixie</EM>'s <STRONG>eventlib</STRONG> (which can be found as a part of
<STRONG>BIND</STRONG> v8).
<P>
<H1><A NAME="BUG_REPORTS_AND_SUPPORT"><font face="Arial,Helvetica">BUG REPORTS AND SUPPORT</A></H1></font>
<P>
If you think you have found a bug in <STRONG>Pth</STRONG>, you should send a report as complete as possible to <EM>bug-pth@gnu.org</EM>. If you can, please try to fix the problem and include a patch, made with
'<CODE>diff -u3</CODE>', in your report. Always, at least, include a reasonable amount of
description in your report to allow the author to deterministically
reproduce the bug.
<P>
For further support you additionally can subscribe to the
<EM>pth-users@gnu.org</EM> mailing list by sending an Email to
<EM>pth-users-request@gnu.org</EM> with `<CODE>subscribe pth-users</CODE>' (or `<CODE>subscribe pth-users</CODE>  <EM>address</EM>' if you want to subscribe from a particular Email <EM>address</EM>) in the body. Then you can discuss your issues with other <STRONG>Pth</STRONG> users by sending messages to
<EM>pth-users@gnu.org</EM>. Currently (as of January 2000) you can reach about 50 Pth users on this
mailing list.
<P>
<H1><A NAME="SEE_ALSO"><font face="Arial,Helvetica">SEE ALSO</A></H1></font>
<P>
<H2><A NAME="Related_Web_Locations"><font face="Arial,Helvetica">Related Web Locations</A></H2></font>
<P>
`comp.programming.threads Newsgroup Archive', <A
HREF="http://www.deja.com/topics_if.xp?">http://www.deja.com/topics_if.xp?</A>
search=topic&amp;group=comp.programming.threads
<P>
`comp.programming.threads Frequently Asked Questions
<FONT SIZE="-1">(F.A.Q.)',</FONT> <A
HREF="http://www.lambdacs.com/newsgroup/FAQ.html">http://www.lambdacs.com/newsgroup/FAQ.html</A>
<P>
`<EM>Multithreading - Definitions and Guidelines</EM>', Numeric Quest Inc 1998; <A
HREF="http://www.numeric-quest.com/lang/multi-frame.html">http://www.numeric-quest.com/lang/multi-frame.html</A>
<P>
`<EM>The Single UNIX Specification, Version 2 - Threads</EM>', The Open Group 1997; <A
HREF="http://www.opengroup.org/onlinepubs">http://www.opengroup.org/onlinepubs</A>
/007908799/xsh/threads.html
<P>
<FONT SIZE="-1">SMI</FONT> Thread Resources, Sun Microsystems Inc; <A
HREF="http://www.sun.com/workshop/threads/">http://www.sun.com/workshop/threads/</A>
<P>
Bibliography on threads and multithreading, Torsten Amundsen; <A
HREF="http://liinwww.ira.uka.de/bibliography/Os/threads.html">http://liinwww.ira.uka.de/bibliography/Os/threads.html</A>
<P>
<H2><A NAME="Related_Books"><font face="Arial,Helvetica">Related Books</A></H2></font>
<P>
<FONT SIZE="-1">B.</FONT> Nichols,
<FONT SIZE="-1">D.</FONT> Buttlar,
<FONT SIZE="-1">J.P.</FONT> Farrel: `
<EM>Pthreads Programming - A POSIX Standard for Better Multiprocessing</EM>', O'Reilly 1996;
<FONT SIZE="-1">ISBN</FONT> 1-56592-115-1
<P>
<FONT SIZE="-1">B.</FONT> Lewis,
<FONT SIZE="-1">D.</FONT>
<FONT SIZE="-1">J.</FONT> Berg: `
<EM>Multithreaded Programming with Pthreads</EM>', Sun Microsystems Press, Prentice Hall 1998;
<FONT SIZE="-1">ISBN</FONT> 0-13-680729-1
<P>
<FONT SIZE="-1">B.</FONT> Lewis,
<FONT SIZE="-1">D.</FONT>
<FONT SIZE="-1">J.</FONT> Berg: `
<EM>Threads Primer - A Guide To Multithreaded Programming</EM>', Prentice Hall 1996;
<FONT SIZE="-1">ISBN</FONT> 0-13-443698-9
<P>
<FONT SIZE="-1">S.</FONT>
<FONT SIZE="-1">J.</FONT> Norton,
<FONT SIZE="-1">M.</FONT>
<FONT SIZE="-1">D.</FONT> Dipasquale: `
<EM>Thread Time - The Multithreaded Programming Guide</EM>', Prentice Hall 1997;
<FONT SIZE="-1">ISBN</FONT> 0-13-190067-6
<P>
<FONT SIZE="-1">D.</FONT>
<FONT SIZE="-1">R.</FONT> Butenhof: `<EM>Programming with POSIX Threads</EM>', Addison Wesley 1997;
<FONT SIZE="-1">ISBN</FONT> 0-201-63392-2
<P>
<H2><A NAME="Related_Manpages"><font face="Arial,Helvetica">Related Manpages</A></H2></font>
<P>
pth-config(1), <CODE>pthread(3).</CODE>
<P>
<CODE>getcontext(2),</CODE> <CODE>setcontext(2),</CODE>
<CODE>makecontext(2),</CODE> <CODE>swapcontext(2),</CODE>
<CODE>sigstack(2),</CODE> <CODE>sigaltstack(2),</CODE>
<CODE>sigaction(2),</CODE> <CODE>sigemptyset(2),</CODE>
<CODE>sigaddset(2),</CODE> <CODE>sigprocmask(2),</CODE>
<CODE>sigsuspend(2),</CODE> <CODE>sigsetjmp(3),</CODE>
<CODE>siglongjmp(3),</CODE> <CODE>setjmp(3),</CODE>
<CODE>longjmp(3),</CODE> <CODE>select(2),</CODE>
<CODE>gettimeofday(2).</CODE>
<P>
<H1><A NAME="AUTHOR"><font face="Arial,Helvetica">AUTHOR</A></H1></font>
<P>
<PRE> Ralf S. Engelschall
 rse@engelschall.com
 www.engelschall.com
</PRE>
<p>
<hr noshade size="1">
<DIV id="sf">
<p>
Please send FSF &amp; GNU inquiries &amp; questions to
<A HREF="mailto:gnu@gnu.org">gnu@gnu.org</A>.
There are also <A HREF="/home.html#ContactInfo">other ways to
contact</A> the FSF.
Please send comments on these web pages to
<A HREF="mailto:webmasters@gnu.org">webmasters@gnu.org</A>,
send other questions to
<A HREF="mailto:gnu@gnu.org">gnu@gnu.org</A>.
Verbatim copying and distribution of this entire article is
permitted in any medium, provided this notice is preserved.<BR>
<p>
<a href="http://www.gnu.org/software/pth/"><img src="pth-icon.jpg" border="0" align="right" alt="" width="126" height="50"></a>
Copyright &copy; 1999-2000 <a href="http://www.gnu.org/people/people.html">Ralf S. Engelschall</A>
<A HREF="mailto:rse@gnu.org">&lt;rse@gnu.org&gt;</A><BR>
Last Modified: 04-07-1999 16:21:23
<p>
Return to <A HREF="/home.html">GNU's home page</A>.
</div>
</blockquote>
</blockquote>
</body>
</html>
